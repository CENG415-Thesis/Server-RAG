{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from modules.agent_state import AgentState\n",
    "from modules.nodes import Nodes\n",
    "\n",
    "def build_stategraph():\n",
    "    builder = StateGraph(AgentState)\n",
    "    \n",
    "    # Adding nodes\n",
    "    builder.add_node(\"user_input\", Nodes.user_input_node)\n",
    "    builder.add_node(\"retrieve\", Nodes.retrieve_node)\n",
    "    builder.add_node(\"generate_response\", Nodes.generate_response_node)\n",
    "    builder.add_node(\"update_memory\", Nodes.update_memory_node)\n",
    "    \n",
    "    # Defining flow\n",
    "    builder.set_entry_point(\"user_input\")\n",
    "    builder.add_edge(\"user_input\", \"retrieve\")\n",
    "    builder.add_edge(\"retrieve\", \"generate_response\")\n",
    "    builder.add_edge(\"generate_response\", \"update_memory\")\n",
    "    builder.add_edge(\"update_memory\", END)\n",
    "    \n",
    "    return builder.compile()\n",
    "\n",
    "def main():\n",
    "    rag_graph = build_stategraph()\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Enter your query: \")\n",
    "        if query.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "        \n",
    "        for step in rag_graph.stream({\"user_query\": query}):\n",
    "            print(\"Response:\", step)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from modules.agent_state import AgentState\n",
    "from modules.nodes import Nodes\n",
    "\n",
    "def build_stategraph():\n",
    "    builder = StateGraph(AgentState)\n",
    "    \n",
    "    # Adding nodes\n",
    "    builder.add_node(\"user_input\", Nodes.user_input_node)\n",
    "    builder.add_node(\"retrieve\", Nodes.retrieve_node)\n",
    "    builder.add_node(\"generate_response\", Nodes.generate_response_node)\n",
    "    builder.add_node(\"update_memory\", Nodes.update_memory_node)\n",
    "    \n",
    "    # Defining flow\n",
    "    builder.set_entry_point(\"user_input\")\n",
    "    builder.add_edge(\"user_input\", \"retrieve\")\n",
    "    builder.add_edge(\"retrieve\", \"generate_response\")\n",
    "    builder.add_edge(\"generate_response\", \"update_memory\")\n",
    "    builder.add_edge(\"update_memory\", END)\n",
    "    \n",
    "    return builder.compile()\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Build the stategraph only once\n",
    "rag_graph = build_stategraph()\n",
    "\n",
    "def process_query1(query):\n",
    "    # Collect responses from the stategraph and join them in a single string.\n",
    "    responses = []\n",
    "    for step in rag_graph.stream({\"user_query\": query}):\n",
    "        responses.append(str(step))\n",
    "    return \"\\n\".join(responses)\n",
    "\n",
    "def process_query(query):\n",
    "    # Collect responses from the stategraph\n",
    "    last_response = None\n",
    "    for step in rag_graph.stream({\"user_query\": query}):\n",
    "        last_response = step  # Keep updating to get the last response\n",
    "    \n",
    "    # Convert the last response to string if it's not already\n",
    "    return str(last_response) if last_response else \"No response generated.\"\n",
    "\n",
    "\n",
    "# Create the Gradio interface.\n",
    "iface = gr.Interface(\n",
    "    fn=process_query,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your query here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"RAG Graph Interface\",\n",
    "    description=\"Enter a query and get a response from the stategraph.\"\n",
    ")\n",
    "\n",
    "# Launch Gradio; for notebooks, share=False usually suffices.\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/25 20:10:58 [W] [service.go:132] login to server failed: i/o deadline reached\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph, END\n",
    "from modules.agent_state import AgentState\n",
    "from modules.nodes import Nodes\n",
    "\n",
    "def build_stategraph():\n",
    "    builder = StateGraph(AgentState)\n",
    "    \n",
    "    # Adding nodes\n",
    "    builder.add_node(\"user_input\", Nodes.user_input_node)\n",
    "    builder.add_node(\"retrieve\", Nodes.retrieve_node)\n",
    "    builder.add_node(\"generate_response\", Nodes.generate_response_node)\n",
    "    builder.add_node(\"update_memory\", Nodes.update_memory_node)\n",
    "    \n",
    "    # Defining flow\n",
    "    builder.set_entry_point(\"user_input\")\n",
    "    builder.add_edge(\"user_input\", \"retrieve\")\n",
    "    builder.add_edge(\"retrieve\", \"generate_response\")\n",
    "    builder.add_edge(\"generate_response\", \"update_memory\")\n",
    "    builder.add_edge(\"update_memory\", END)\n",
    "    \n",
    "    return builder.compile()\n",
    "\n",
    "# Create the StateGraph\n",
    "rag_graph = build_stategraph()\n",
    "\n",
    "def respond(message, history):\n",
    "    # Run the graph and get the final state\n",
    "    final_state = rag_graph.invoke({\"user_query\": message})\n",
    "    \n",
    "    # Extract the AI's response from the final state\n",
    "    # Adjust this based on your AgentState structure\n",
    "    ai_response = final_state.get(\"response\", \"I don't have an answer for that.\")\n",
    "    \n",
    "    return ai_response\n",
    "\n",
    "# Create and launch the Gradio interface\n",
    "demo = gr.ChatInterface(\n",
    "    fn=respond,\n",
    "    title=\"LangGraph RAG Assistant\",\n",
    "    description=\"Ask me anything and I'll use a retrieval-augmented generation system to answer.\",\n",
    "    examples=[\"Tell me about machine learning\", \"What is LangGraph?\", \"How does RAG work?\"],\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
