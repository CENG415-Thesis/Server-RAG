{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Create Gradio interface with tabs for different functions\\nwith gr.Blocks(title=\"IZTECH Telecom RAG Server 🤖\", theme=gr.themes.Soft()) as demo:   \\n    with gr.Tabs():\\n        # PDF Upload Tab\\n        with gr.TabItem(\"PDF Upload\"):\\n            \\n            with gr.Row():\\n                gr.Markdown(\"Upload PDF files to update the vector database with new documents. Duplicate files will be skipped.\")\\n            \\n            with gr.Row():\\n                pdf_input = gr.File(\\n                    file_count=\"multiple\", \\n                    file_types=[\\'.pdf\\'], \\n                    label=\"Upload PDF Files\"\\n                )\\n            \\n            with gr.Row():\\n                process_btn = gr.Button(\"ADD to Vector DB\")\\n                status_output = gr.Textbox(label=\"Processing Status\", interactive=False)\\n            \\n            with gr.Row(elem_classes=\"center-row\"):\\n                files_list = gr.DataFrame(\\n                    headers=[\"Filename\", \"Size (KB)\", \"Upload Date\"],\\n                    datatype=[\"str\", \"str\", \"str\"],\\n                    label=\"Uploaded PDFs\",\\n                    interactive=False\\n                )\\n\\n            # Connect process button to process_pdfs function\\n            process_btn.click(\\n                fn=process_pdfs,\\n                inputs=[pdf_input],\\n                outputs=[status_output]\\n            ).then(\\n                fn=list_uploaded_files,\\n                outputs=[files_list]\\n            )\\n\\n            # Initialize the files list on page load\\n            demo.load(\\n                fn=list_uploaded_files,\\n                outputs=[files_list]\\n            )\\n        \\n        # Chat Tab\\n        with gr.TabItem(\"Chat\"):\\n            chatbot = gr.ChatInterface(\\n                fn=respond,\\n                title=\"IZTECH-Server Telecom RAG Assistant 🤖\",\\n            )\\n\\n# Launch the application\\nif __name__ == \"__main__\":\\n    demo.launch(share=True)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Import the shared state and nodes modules\n",
    "from modules.agent_state import AgentState\n",
    "from modules.nodes import Nodes\n",
    "\n",
    "# Environment setup\n",
    "load_dotenv()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Directory paths\n",
    "VECTOR_STORE_PATH = \"vector-db\"\n",
    "UPLOADED_FILES_DIR = \"uploaded_files\"\n",
    "HASH_FILE_PATH = \"uploaded_files/file_hashes.txt\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(VECTOR_STORE_PATH, exist_ok=True)\n",
    "os.makedirs(UPLOADED_FILES_DIR, exist_ok=True)\n",
    "\n",
    "def get_file_hash(file_path):\n",
    "    \"\"\"Calculate MD5 hash of a file to identify duplicates\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def load_existing_hashes():\n",
    "    \"\"\"Load existing file hashes from storage\"\"\"\n",
    "    if not os.path.exists(HASH_FILE_PATH):\n",
    "        return {}\n",
    "    \n",
    "    file_hashes = {}\n",
    "    try:\n",
    "        with open(HASH_FILE_PATH, \"r\") as f:\n",
    "            for line in f:\n",
    "                if \":\" in line:\n",
    "                    hash_value, filename = line.strip().split(\":\", 1)\n",
    "                    file_hashes[hash_value] = filename\n",
    "    except Exception:\n",
    "        # If there's an error reading the file, start fresh\n",
    "        file_hashes = {}\n",
    "    \n",
    "    return file_hashes\n",
    "\n",
    "def save_file_hash(file_hash, filename):\n",
    "    \"\"\"Save a new file hash to storage\"\"\"\n",
    "    with open(HASH_FILE_PATH, \"a+\") as f:\n",
    "        f.write(f\"{file_hash}:{filename}\\n\")\n",
    "\n",
    "class ServerNodes:\n",
    "    \"\"\"Server-specific nodes for the StateGraph\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_pdf_node(state):\n",
    "        \"\"\"Node to load and process PDF files\"\"\"\n",
    "        pdf_files = state.get(\"pdf_files\", [])\n",
    "        if not pdf_files:\n",
    "            return {\"status\": \"No PDF files provided\", **state}\n",
    "        \n",
    "        all_documents = []\n",
    "        # Load each PDF\n",
    "        for pdf_file in pdf_files:\n",
    "            try:\n",
    "                loader = PyPDFLoader(pdf_file)\n",
    "                documents = loader.load()\n",
    "                all_documents.extend(documents)\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"status\": f\"Error loading PDF {pdf_file}: {str(e)}\", \n",
    "                    # Add a placeholder response to satisfy the state requirements\n",
    "                    \"response\": f\"Error loading PDF: {str(e)}\",\n",
    "                    **state\n",
    "                }\n",
    "        \n",
    "        # Split documents\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "        split_docs = text_splitter.split_documents(all_documents)\n",
    "        \n",
    "        return {\n",
    "            \"status\": f\"Successfully loaded {len(pdf_files)} PDF(s) with {len(split_docs)} chunks\",\n",
    "            \"documents\": split_docs,\n",
    "            # Add a placeholder response to satisfy the state requirements\n",
    "            \"response\": f\"Successfully loaded {len(pdf_files)} PDF(s) with {len(split_docs)} chunks\",\n",
    "            **state\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def update_vector_store_node(state):\n",
    "        \"\"\"Node to update the vector store with new documents\"\"\"\n",
    "        documents = state.get(\"documents\", [])\n",
    "        if not documents:\n",
    "            return {\n",
    "                \"status\": \"No documents to add to vector store\", \n",
    "                # Add a placeholder response to satisfy the state requirements\n",
    "                \"response\": \"No documents to add to vector store\",\n",
    "                **state\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings\n",
    "            embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") \n",
    "            \n",
    "            # Check if vector store exists\n",
    "            if os.path.exists(VECTOR_STORE_PATH):\n",
    "                # Load existing vector store\n",
    "                vector_store = Chroma(persist_directory=VECTOR_STORE_PATH, embedding_function=embeddings)\n",
    "                # Add new documents\n",
    "                vector_store.add_documents(documents)\n",
    "            else:\n",
    "                # Create new vector store\n",
    "                vector_store = Chroma.from_documents(\n",
    "                    documents=documents,\n",
    "                    embedding=embeddings,\n",
    "                    persist_directory=VECTOR_STORE_PATH\n",
    "                )\n",
    "            \n",
    "            # Persist changes\n",
    "            vector_store.persist()\n",
    "            \n",
    "            success_message = f\"Successfully updated vector store with {len(documents)} documents\"\n",
    "            return {\n",
    "                \"status\": success_message,\n",
    "                \"vector_store\": vector_store,\n",
    "                # Add a placeholder response to satisfy the state requirements\n",
    "                \"response\": success_message,\n",
    "                **state\n",
    "            }\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error updating vector store: {str(e)}\"\n",
    "            return {\n",
    "                \"status\": error_message,\n",
    "                # Add a placeholder response to satisfy the state requirements\n",
    "                \"response\": error_message,\n",
    "                **state\n",
    "            }\n",
    "\n",
    "def build_server_stategraph():\n",
    "    \"\"\"Build the StateGraph for the server\"\"\"\n",
    "    builder = StateGraph(AgentState)\n",
    "    \n",
    "    # Add server-specific nodes\n",
    "    builder.add_node(\"load_pdf\", ServerNodes.load_pdf_node)\n",
    "    builder.add_node(\"update_vector_store\", ServerNodes.update_vector_store_node)\n",
    "    \n",
    "    # Add shared nodes (for chat functionality)\n",
    "    builder.add_node(\"user_input\", Nodes.user_input_node)\n",
    "    builder.add_node(\"retrieve\", Nodes.retrieve_node)\n",
    "    builder.add_node(\"generate_response\", Nodes.generate_response_node)\n",
    "    builder.add_node(\"update_memory\", Nodes.update_memory_node)\n",
    "    \n",
    "    # Define PDF processing flow\n",
    "    builder.add_conditional_edges(\n",
    "        \"user_input\",\n",
    "        lambda state: \"load_pdf\" if state.get(\"pdf_files\") else \"retrieve\"\n",
    "    )\n",
    "    builder.add_edge(\"load_pdf\", \"update_vector_store\")\n",
    "    builder.add_edge(\"update_vector_store\", END)\n",
    "    \n",
    "    # Define chat flow\n",
    "    builder.add_edge(\"retrieve\", \"generate_response\")\n",
    "    builder.add_edge(\"generate_response\", \"update_memory\")\n",
    "    builder.add_edge(\"update_memory\", END)\n",
    "    \n",
    "    # Set entry point\n",
    "    builder.set_entry_point(\"user_input\")\n",
    "    \n",
    "    return builder.compile()\n",
    "\n",
    "# Create a separate graph for PDF processing to avoid state validation issues\n",
    "def build_pdf_processing_graph():\n",
    "    \"\"\"Build a separate StateGraph just for PDF processing\"\"\"\n",
    "    # Create a custom state class for PDF processing that doesn't require the same fields\n",
    "    class PDFProcessState(dict):\n",
    "        pass\n",
    "    \n",
    "    builder = StateGraph(PDFProcessState)\n",
    "    \n",
    "    # Add PDF processing nodes\n",
    "    builder.add_node(\"load_pdf\", ServerNodes.load_pdf_node)\n",
    "    builder.add_node(\"update_vector_store\", ServerNodes.update_vector_store_node)\n",
    "    \n",
    "    # Define flow\n",
    "    builder.set_entry_point(\"load_pdf\")\n",
    "    builder.add_edge(\"load_pdf\", \"update_vector_store\")\n",
    "    builder.add_edge(\"update_vector_store\", END)\n",
    "    \n",
    "    return builder.compile()\n",
    "\n",
    "# Create the StateGraphs\n",
    "server_graph = build_server_stategraph()\n",
    "pdf_process_graph = build_pdf_processing_graph()\n",
    "\n",
    "\n",
    "def save_uploaded_files(files):\n",
    "    \"\"\"Save uploaded files to the designated directory and return their paths\"\"\"\n",
    "    saved_paths = []\n",
    "    duplicate_files = []\n",
    "    existing_hashes = load_existing_hashes()\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        # Calculate file hash to check for duplicates\n",
    "        file_hash = get_file_hash(file.name)\n",
    "        \n",
    "        # Check if this file has been uploaded before\n",
    "        if file_hash in existing_hashes:\n",
    "            duplicate_files.append(os.path.basename(file.name))\n",
    "            continue\n",
    "        \n",
    "        # Create a unique filename with timestamp\n",
    "        original_filename = os.path.basename(file.name)\n",
    "        filename_without_ext, extension = os.path.splitext(original_filename)\n",
    "        new_filename = f\"{filename_without_ext}_{timestamp}_{i}{extension}\"\n",
    "        \n",
    "        # Define the save path\n",
    "        save_path = os.path.join(UPLOADED_FILES_DIR, new_filename)\n",
    "        \n",
    "        # Copy the file to the uploads directory\n",
    "        shutil.copy2(file.name, save_path)\n",
    "        saved_paths.append(save_path)\n",
    "        \n",
    "        # Save the hash to prevent future duplicates\n",
    "        save_file_hash(file_hash, new_filename)\n",
    "    \n",
    "    return saved_paths, duplicate_files\n",
    "\"\"\" \n",
    "def delete_pdf(pdf_filename):\n",
    "    remove_pdf_from_vectorstore(pdf_filename)\n",
    "    return list_uploaded_files()\n",
    "\"\"\"\n",
    "def list_uploaded_files():\n",
    "    \"\"\"List all previously uploaded PDF files with a delete button\"\"\"\n",
    "    if not os.path.exists(UPLOADED_FILES_DIR):\n",
    "        return {\"data\": [], \"headers\": [\"Filename\", \"Size (KB)\", \"Upload Date\"]}\n",
    "\n",
    "    files_data = []\n",
    "    for filename in os.listdir(UPLOADED_FILES_DIR):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            file_path = os.path.join(UPLOADED_FILES_DIR, filename)\n",
    "            # Get file stats\n",
    "            file_stats = os.stat(file_path)\n",
    "            size_kb = file_stats.st_size / 1024\n",
    "            upload_date = datetime.fromtimestamp(file_stats.st_mtime).strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "            # Add delete button reference\n",
    "            files_data.append([filename, f\"{size_kb:.1f}\", upload_date])\n",
    "\n",
    "    # Sort by upload date (newest first)\n",
    "    files_data.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return {\"data\": files_data, \"headers\": [\"Filename\", \"Size (KB)\", \"Upload Date\"]}\n",
    "\n",
    "\n",
    "\n",
    "from helpers.config import vectorstore\n",
    "\n",
    "def remove_pdf_from_vectorstore(pdf_filename: str):\n",
    "    all_docs = vectorstore.get()\n",
    "\n",
    "    # Debugging: Print or log all_docs to understand its structure\n",
    "    print(f\"Vector store response: {all_docs}\")\n",
    "\n",
    "    if not isinstance(all_docs, dict) or \"documents\" not in all_docs:\n",
    "        print(\"Error: Unexpected vector store response format.\")\n",
    "        return\n",
    "    \n",
    "    # Ensure 'documents' is a list\n",
    "    documents = all_docs.get(\"documents\", [])\n",
    "    if not isinstance(documents, list):\n",
    "        print(\"Error: 'documents' key does not contain a list.\")\n",
    "        return\n",
    "    \n",
    "    # Extract IDs to remove\n",
    "    doc_ids_to_remove = [\n",
    "        doc[\"id\"] for doc in documents \n",
    "        if isinstance(doc, dict) and doc.get(\"metadata\", {}).get(\"source\") == pdf_filename\n",
    "    ]\n",
    "\n",
    "    if not doc_ids_to_remove:\n",
    "        print(f\"⚠️ {pdf_filename} not found in vectorstore.\")\n",
    "        return\n",
    "    \n",
    "    vectorstore.delete(doc_ids_to_remove)\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    print(f\"❌ {pdf_filename} removed successfully!\")\n",
    "    \n",
    "def get_collection_count():\n",
    "    return vectorstore._chroma_collection.count()\n",
    "    \n",
    "\n",
    "\"\"\" \n",
    "def remove_pdf_from_vectorstore(pdf_filename: str):\n",
    "    all_docs = vectorstore.get()\n",
    "    \n",
    "    # Silinecek belgeleri filtreleme\n",
    "    doc_ids_to_remove = [doc[\"id\"] for doc in all_docs[\"documents\"] if doc[\"metadata\"].get(\"source\") == pdf_filename]\n",
    "    \n",
    "    if not doc_ids_to_remove:\n",
    "        print(f\"⚠️ {pdf_filename} not found in vectorstore.\")\n",
    "        return\n",
    "    \n",
    "    vectorstore.delete(doc_ids_to_remove)\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    print(f\"❌ {pdf_filename} removed successfully!\")\n",
    "\"\"\"\n",
    "\n",
    "def process_pdfs(pdf_files):\n",
    "    \"\"\"Process uploaded PDF files and update the vector store\"\"\"\n",
    "    if not pdf_files:\n",
    "        return \"No PDF files uploaded\"\n",
    "    \n",
    "    # Save the uploaded files to the upload directory, checking for duplicates\n",
    "    saved_paths, duplicate_files = save_uploaded_files(pdf_files)\n",
    "    \n",
    "    # Handle case where all files are duplicates\n",
    "    if not saved_paths and duplicate_files:\n",
    "        return f\"All files are duplicates and were not uploaded again: {', '.join(duplicate_files)}\"\n",
    "    \n",
    "    # Handle case with some duplicates\n",
    "    duplicate_message = \"\"\n",
    "    if duplicate_files:\n",
    "        duplicate_message = f\"\\nSkipped duplicate files: {', '.join(duplicate_files)}\"\n",
    "    \n",
    "    # If no new files after duplicate check\n",
    "    if not saved_paths:\n",
    "        return f\"No new files to process.{duplicate_message}\"\n",
    "    \n",
    "    try:\n",
    "        # Use the dedicated PDF processing graph instead of the main server graph\n",
    "        final_state = pdf_process_graph.invoke({\n",
    "            \"pdf_files\": saved_paths\n",
    "        })\n",
    "        \n",
    "        status = final_state.get(\"status\", \"Processing completed\")\n",
    "        return f\"{status}\\nFiles saved to {UPLOADED_FILES_DIR} directory.{duplicate_message}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing PDFs: {str(e)}\\nFiles were saved to {UPLOADED_FILES_DIR} directory.{duplicate_message}\"\n",
    "\n",
    "def respond(message, history):\n",
    "    \"\"\"Handle chat interaction\"\"\"\n",
    "    # Run the graph with user query\n",
    "    final_state = server_graph.invoke({\n",
    "        \"user_query\": message\n",
    "    })\n",
    "    \n",
    "    # Extract the AI's response\n",
    "    ai_response = final_state.get(\"response\", \"I don't have an answer for that.\")\n",
    "    \n",
    "    return ai_response\n",
    "\"\"\" \n",
    "# Create Gradio interface with tabs for different functions\n",
    "with gr.Blocks(title=\"IZTECH Telecom RAG Server 🤖\", theme=gr.themes.Soft()) as demo:   \n",
    "    with gr.Tabs():\n",
    "        # PDF Upload Tab\n",
    "        with gr.TabItem(\"PDF Upload\"):\n",
    "            \n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"Upload PDF files to update the vector database with new documents. Duplicate files will be skipped.\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                pdf_input = gr.File(\n",
    "                    file_count=\"multiple\", \n",
    "                    file_types=['.pdf'], \n",
    "                    label=\"Upload PDF Files\"\n",
    "                )\n",
    "            \n",
    "            with gr.Row():\n",
    "                process_btn = gr.Button(\"ADD to Vector DB\")\n",
    "                status_output = gr.Textbox(label=\"Processing Status\", interactive=False)\n",
    "            \n",
    "            with gr.Row(elem_classes=\"center-row\"):\n",
    "                files_list = gr.DataFrame(\n",
    "                    headers=[\"Filename\", \"Size (KB)\", \"Upload Date\"],\n",
    "                    datatype=[\"str\", \"str\", \"str\"],\n",
    "                    label=\"Uploaded PDFs\",\n",
    "                    interactive=False\n",
    "                )\n",
    "\n",
    "            # Connect process button to process_pdfs function\n",
    "            process_btn.click(\n",
    "                fn=process_pdfs,\n",
    "                inputs=[pdf_input],\n",
    "                outputs=[status_output]\n",
    "            ).then(\n",
    "                fn=list_uploaded_files,\n",
    "                outputs=[files_list]\n",
    "            )\n",
    "\n",
    "            # Initialize the files list on page load\n",
    "            demo.load(\n",
    "                fn=list_uploaded_files,\n",
    "                outputs=[files_list]\n",
    "            )\n",
    "        \n",
    "        # Chat Tab\n",
    "        with gr.TabItem(\"Chat\"):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=respond,\n",
    "                title=\"IZTECH-Server Telecom RAG Assistant 🤖\",\n",
    "            )\n",
    "\n",
    "# Launch the application\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def delete_selected_pdfs(selected_files):\n",
    "    if not selected_files:\n",
    "        return \"No files selected for deletion.\"\n",
    "    \n",
    "    for pdf_filename in selected_files:\n",
    "        # Remove from vector store\n",
    "        remove_pdf_from_vectorstore(pdf_filename)\n",
    "        \n",
    "        # Remove from filesystem\n",
    "        pdf_path = os.path.join(UPLOADED_FILES_DIR, pdf_filename)\n",
    "        if os.path.exists(pdf_path):\n",
    "            os.remove(pdf_path)\n",
    "    \n",
    "    return f\"Deleted: {', '.join(selected_files)}\"\n",
    "\n",
    "def update_table():\n",
    "    \"\"\"Fetch updated PDF file list for display.\"\"\"\n",
    "    data = list_uploaded_files()\n",
    "    return gr.update(value={\"data\": data[\"data\"], \"headers\": data[\"headers\"]})\n",
    "\n",
    "def interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## PDF File Management\")\n",
    "        \n",
    "        # Table display\n",
    "        pdf_table = gr.Dataframe(value=list_uploaded_files(), interactive=False, type=\"array\")\n",
    "        collection_num =get_collection_count()\n",
    "        \n",
    "        gr.Textbox(f\"Total documents in vector store: {collection_num}\", interactive=False)\n",
    "        # Checkbox group for selecting PDFs\n",
    "        pdf_selector = gr.CheckboxGroup(choices=[], label=\"Select PDFs to delete\")\n",
    "        \n",
    "        # Button to delete selected PDFs\n",
    "        delete_button = gr.Button(\"Delete Selected PDFs\")\n",
    "        \n",
    "        # Update the checkbox choices when the table updates\n",
    "        def update_checkbox_choices():\n",
    "            pdf_files = [row[0] for row in list_uploaded_files()[\"data\"]]  # Extract filenames\n",
    "            return gr.update(choices=pdf_files)\n",
    "        \n",
    "        # Button click event\n",
    "        delete_button.click(delete_selected_pdfs, inputs=[pdf_selector], outputs=[pdf_table])\n",
    "        \n",
    "        # Automatically update checkboxes\n",
    "        pdf_table.change(update_checkbox_choices, outputs=[pdf_selector])\n",
    "        \n",
    "    return demo\n",
    "\n",
    "demo = interface()\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/02 13:48:29 [W] [service.go:132] login to server failed: i/o deadline reached\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks(title=\"IZTECH Telecom RAG Server 🤖\", theme=gr.themes.Soft()) as demo:   \n",
    "    with gr.Tabs():\n",
    "        # 📌 PDF Upload Tab\n",
    "        with gr.TabItem(\"PDF Upload\"):\n",
    "            \n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"Upload PDF files to update the vector database with new documents. Duplicate files will be skipped.\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                pdf_input = gr.File(\n",
    "                    file_count=\"multiple\", \n",
    "                    file_types=['.pdf'], \n",
    "                    label=\"Upload PDF Files\"\n",
    "                )\n",
    "            \n",
    "            with gr.Row():\n",
    "                process_btn = gr.Button(\"ADD to Vector DB\")\n",
    "                status_output = gr.Textbox(label=\"Processing Status\", interactive=False)\n",
    "            \n",
    "            # 📌 PDF Listesi (Checkbox ile)\n",
    "            with gr.Row(elem_classes=\"center-row\"):\n",
    "                files_list = gr.DataFrame(\n",
    "                    headers=[\"Select\", \"Filename\", \"Size (KB)\", \"Upload Date\"],\n",
    "                    datatype=[\"bool\", \"str\", \"str\", \"str\"],\n",
    "                    label=\"Uploaded PDFs\",\n",
    "                    interactive=True  # Checkboxları aktif etmek için\n",
    "                )\n",
    "\n",
    "            # 📌 Seçilen dosyaların listesi\n",
    "            selected_pdfs = gr.Textbox(label=\"Selected Files\", interactive=False)\n",
    "\n",
    "            # 📌 Silme Butonu\n",
    "            with gr.Row():\n",
    "                delete_button = gr.Button(\"Delete Selected PDFs\", variant=\"stop\")\n",
    "\n",
    "            # 📌 Kullanıcı seçim yaptığında seçilenleri listeye ekleyelim\n",
    "            def update_selected_pdfs(selected_rows):\n",
    "                \"\"\"Seçilen satırlardan PDF isimlerini alır ve liste halinde döndürür\"\"\"\n",
    "                if not selected_rows:\n",
    "                    return \"\"  # Hiç seçim yoksa boş bırak\n",
    "\n",
    "                selected_filenames = [row[1] for row in selected_rows if row[0]]  # Checkbox seçili olanlar\n",
    "                return \", \".join(selected_filenames)  # Listeyi string olarak dön\n",
    "\n",
    "            files_list.select(\n",
    "                fn=update_selected_pdfs,\n",
    "                outputs=[selected_pdfs]\n",
    "            )\n",
    "\n",
    "            # 📌 Seçilen PDF'leri sil\n",
    "            def delete_selected_pdfs(selected_files_str):\n",
    "                \"\"\"Listedeki tüm PDF'leri sil ve tabloyu güncelle\"\"\"\n",
    "                if not selected_files_str:\n",
    "                    return list_uploaded_files()  # Seçim yoksa tabloyu güncelle\n",
    "\n",
    "                selected_files = selected_files_str.split(\", \")  # String -> Liste\n",
    "\n",
    "                print(f\"📌 Siliniyor: {selected_files}\")  # Debugging için\n",
    "                for pdf_filename in selected_files:\n",
    "                    remove_pdf_from_vectorstore(pdf_filename)\n",
    "\n",
    "                return list_uploaded_files()  # Yeni tabloyu döndür\n",
    "\n",
    "            delete_button.click(\n",
    "                fn=delete_selected_pdfs,\n",
    "                inputs=[selected_pdfs],\n",
    "                outputs=[files_list]\n",
    "            )\n",
    "\n",
    "            # 📌 Sayfa yüklendiğinde PDF listesini göster\n",
    "            demo.load(\n",
    "                fn=list_uploaded_files,\n",
    "                outputs=[files_list]\n",
    "            )\n",
    "        \n",
    "        # 📌 Chat Tab\n",
    "        with gr.TabItem(\"Chat\"):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=respond,\n",
    "                title=\"IZTECH-Server Telecom RAG Assistant 🤖\",\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# Launch the application\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(pdf_process_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title=\"IZTECH Telecom RAG Server 🤖\", theme=gr.themes.Soft()) as demo:   \n",
    "    with gr.Tabs():\n",
    "        # PDF Upload Tab\n",
    "        with gr.TabItem(\"PDF Upload\"):\n",
    "            \n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"Upload PDF files to update the vector database with new documents. Duplicate files will be skipped.\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                pdf_input = gr.File(\n",
    "                    file_count=\"multiple\", \n",
    "                    file_types=['.pdf'], \n",
    "                    label=\"Upload PDF Files\"\n",
    "                )\n",
    "            \n",
    "            with gr.Row():\n",
    "                process_btn = gr.Button(\"ADD to Vector DB\")\n",
    "                status_output = gr.Textbox(label=\"Processing Status\", interactive=False)\n",
    "            \n",
    "            with gr.Row(elem_classes=\"center-row\"):\n",
    "                files_list = gr.DataFrame(\n",
    "                    headers=[\"Filename\", \"Size (KB)\", \"Upload Date\", \"Actions\"],\n",
    "                    datatype=[\"str\", \"str\", \"str\", \"str\"],\n",
    "                    label=\"Uploaded PDFs\",\n",
    "                    interactive=False\n",
    "                )\n",
    "\n",
    "            delete_button = gr.Button(\"Delete Selected PDF\")\n",
    "            selected_pdf = gr.Textbox(visible=False)  # Hidden textbox for filename storage\n",
    "\n",
    "            # Connect process button to process_pdfs function\n",
    "            process_btn.click(\n",
    "                fn=process_pdfs,\n",
    "                inputs=[pdf_input],\n",
    "                outputs=[status_output]\n",
    "            ).then(\n",
    "                fn=list_uploaded_files,\n",
    "                outputs=[files_list]\n",
    "            )\n",
    "\n",
    "            # Select PDF from table for deletion\n",
    "            files_list.select(\n",
    "                fn=lambda row: row[0],  # Select filename\n",
    "                outputs=[selected_pdf]\n",
    "            )\n",
    "\n",
    "            # Delete button callback\n",
    "            delete_button.click(\n",
    "                fn=delete_pdf,\n",
    "                inputs=[selected_pdf],\n",
    "                outputs=[files_list]\n",
    "            )\n",
    "\n",
    "            # Initialize the files list on page load\n",
    "            demo.load(\n",
    "                fn=list_uploaded_files,\n",
    "                outputs=[files_list]\n",
    "            )\n",
    "        \n",
    "        # Chat Tab\n",
    "        with gr.TabItem(\"Chat\"):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=respond,\n",
    "                title=\"IZTECH-Server Telecom RAG Assistant 🤖\",\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
