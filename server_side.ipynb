{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c4479c-576f-4d56-bdf0-2c5897a0c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "#from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from get_upload_func import save_uploaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd3dd2-c567-4197-b635-071499e65ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymupdf\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "def save_uploaded_file(pdf_file, embed_method, db_name=\"vector-db\", uploaded_files_dir=\"uploaded_files\"):\n",
    "    \"\"\"\n",
    "    Y羹klenen PDF dosyas覺n覺 belirtilen klas繹re kaydeder, metni iler ve vekt繹r veritaban覺na ekler.\n",
    "    \n",
    "    :param pdf_file: gradio taraf覺ndan y羹klenen dosya objesi\n",
    "    :param embed_method: Se癟ilen embedding y繹ntemi\n",
    "    :param db_name: Vekt繹r veritaban覺n覺n ad覺 (varsay覺lan: \"vector-db\")\n",
    "    :param uploaded_files_dir: Kaydedilecek ana dizin (varsay覺lan: \"uploaded_files\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Klas繹r olutur\n",
    "        os.makedirs(uploaded_files_dir, exist_ok=True)\n",
    "        save_path = os.path.join(uploaded_files_dir, pdf_file.name)\n",
    "        \n",
    "        # PDF dosyas覺n覺 kaydet\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(pdf_file.read())\n",
    "        \n",
    "        \n",
    "        # PDF dosyas覺n覺 ile\n",
    "        pdf_open = pymupdf.open(save_path)\n",
    "        toc = pdf_open.get_toc()\n",
    "        chunked_documents = []\n",
    "                \n",
    "        for i, item in enumerate(toc):\n",
    "            heading = item[1]\n",
    "            start_page = item[2]\n",
    "            \n",
    "            if i + 1 < len(toc):\n",
    "                end_page = toc[i + 1][2] - 1\n",
    "            else:\n",
    "                end_page = pdf_open.page_count - 1  # Son bal覺ksa son sayfaya kadar\n",
    "            \n",
    "            chunk_text = \"\"\n",
    "            for page_num in range(start_page, end_page + 1):\n",
    "                chunk_text += pdf_open[page_num].get_text()\n",
    "            \n",
    "            chunked_documents.append(\n",
    "                Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata={\"heading\": heading, \"start_page\": start_page, \"end_page\": end_page}\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Vekt繹r veritaban覺na ekleme\n",
    "        vectorstore = Chroma(persist_directory=db_name, embedding_function=embed_method)\n",
    "        vectorstore.add_documents(chunked_documents)\n",
    "        \n",
    "        return f\"{pdf_file.name} baar覺yla ilendi ve vekt繹r veritaban覺na eklendi!\"\n",
    "    except Exception as e:\n",
    "        return f\"Hata: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86b667c-1a85-477e-be31-f592e1b33607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://6c08e2c78f9cd633c4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6c08e2c78f9cd633c4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "#burada get_uploaded_func yerine yukar覺daki methodu kulland覺k,  baar覺yla iledim diyor ama uploaded_files alt覺nda pdf yok.\n",
    "\n",
    "# Vector database name\n",
    "DB_NAME = \"vector-db\"\n",
    "\n",
    "# Embedding methods\n",
    "embed_methods = {\n",
    "    \"Ollama - Nomic Embed\": OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "}\n",
    "\n",
    "def process_upload(uploaded_file, selected_embed):\n",
    "    try:\n",
    "        embeddings = embed_methods[selected_embed]\n",
    "        save_uploaded_file(uploaded_file, embeddings, DB_NAME)\n",
    "        return f\"{uploaded_file.name} has been successfully added to the vector database!\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Load vector database\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma(persist_directory=DB_NAME, embedding_function=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Load LLM model\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Chat Memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "def query_rag_pipeline(user_query, history):\n",
    "    # Retrieve chat history\n",
    "    chat_history = memory.load_memory_variables({}).get(\"history\", \"\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = vectorstore.similarity_search(user_query, k=10)\n",
    "    combined_context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    # Prompt format\n",
    "    prompt = f\"\"\"\n",
    "    You are a telecom assistant. Your answers should be based on the context and chat history provided. If the context is not relevant to the user's query, politely state that you do not have the required information.\n",
    "\n",
    "    Chat History: {chat_history}\n",
    "    \n",
    "    Context: {combined_context}\n",
    "    \n",
    "    Question: {user_query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Update chat memory\n",
    "    memory.save_context({\"input\": user_query}, {\"output\": response})\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Server-Side RAG Assistant \")\n",
    "    \n",
    "    with gr.Row():\n",
    "        selected_embed = gr.Dropdown(choices=list(embed_methods.keys()), label=\"Select Embedding Method\")\n",
    "        file_uploader = gr.File(label=\"Upload a PDF\")\n",
    "        upload_button = gr.Button(\"Upload\")\n",
    "    \n",
    "    upload_output = gr.Textbox(label=\"Upload Status\")\n",
    "    upload_button.click(process_upload, inputs=[file_uploader, selected_embed], outputs=upload_output)\n",
    "    \n",
    "    \n",
    "    chatbot = gr.ChatInterface(fn=query_rag_pipeline, title=\"Chatbot Assistant\", type=\"messages\")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623cab3-e061-4ef5-b352-90899060d747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
