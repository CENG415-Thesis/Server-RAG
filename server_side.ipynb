{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c4479c-576f-4d56-bdf0-2c5897a0c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "#from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from get_upload_func import save_uploaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd3dd2-c567-4197-b635-071499e65ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymupdf\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "def save_uploaded_file(pdf_file, embed_method, db_name=\"vector-db\", uploaded_files_dir=\"uploaded_files\"):\n",
    "    \"\"\"\n",
    "    Yüklenen PDF dosyasını belirtilen klasöre kaydeder, metni işler ve vektör veritabanına ekler.\n",
    "    \n",
    "    :param pdf_file: gradio tarafından yüklenen dosya objesi\n",
    "    :param embed_method: Seçilen embedding yöntemi\n",
    "    :param db_name: Vektör veritabanının adı (varsayılan: \"vector-db\")\n",
    "    :param uploaded_files_dir: Kaydedilecek ana dizin (varsayılan: \"uploaded_files\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Klasör oluştur\n",
    "        os.makedirs(uploaded_files_dir, exist_ok=True)\n",
    "        save_path = os.path.join(uploaded_files_dir, pdf_file.name)\n",
    "        \n",
    "        # PDF dosyasını kaydet\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(pdf_file.read())\n",
    "        \n",
    "        \n",
    "        # PDF dosyasını işle\n",
    "        pdf_open = pymupdf.open(save_path)\n",
    "        toc = pdf_open.get_toc()\n",
    "        chunked_documents = []\n",
    "                \n",
    "        for i, item in enumerate(toc):\n",
    "            heading = item[1]\n",
    "            start_page = item[2]\n",
    "            \n",
    "            if i + 1 < len(toc):\n",
    "                end_page = toc[i + 1][2] - 1\n",
    "            else:\n",
    "                end_page = pdf_open.page_count - 1  # Son başlıksa son sayfaya kadar\n",
    "            \n",
    "            chunk_text = \"\"\n",
    "            for page_num in range(start_page, end_page + 1):\n",
    "                chunk_text += pdf_open[page_num].get_text()\n",
    "            \n",
    "            chunked_documents.append(\n",
    "                Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata={\"heading\": heading, \"start_page\": start_page, \"end_page\": end_page}\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Vektör veritabanına ekleme\n",
    "        vectorstore = Chroma(persist_directory=db_name, embedding_function=embed_method)\n",
    "        vectorstore.add_documents(chunked_documents)\n",
    "        \n",
    "        return f\"{pdf_file.name} başarıyla işlendi ve vektör veritabanına eklendi!\"\n",
    "    except Exception as e:\n",
    "        return f\"Hata: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c86b667c-1a85-477e-be31-f592e1b33607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://6c08e2c78f9cd633c4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6c08e2c78f9cd633c4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "#burada get_uploaded_func yerine yukarıdaki methodu kullandık,  başarıyla işledim diyor ama uploaded_files altında pdf yok.\n",
    "\n",
    "# Vector database name\n",
    "DB_NAME = \"vector-db\"\n",
    "\n",
    "# Embedding methods\n",
    "embed_methods = {\n",
    "    \"Ollama - Nomic Embed\": OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "}\n",
    "\n",
    "def process_upload(uploaded_file, selected_embed):\n",
    "    try:\n",
    "        embeddings = embed_methods[selected_embed]\n",
    "        save_uploaded_file(uploaded_file, embeddings, DB_NAME)\n",
    "        return f\"{uploaded_file.name} has been successfully added to the vector database!\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Load vector database\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma(persist_directory=DB_NAME, embedding_function=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Load LLM model\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Chat Memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "def query_rag_pipeline(user_query, history):\n",
    "    # Retrieve chat history\n",
    "    chat_history = memory.load_memory_variables({}).get(\"history\", \"\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = vectorstore.similarity_search(user_query, k=10)\n",
    "    combined_context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    # Prompt format\n",
    "    prompt = f\"\"\"\n",
    "    You are a telecom assistant. Your answers should be based on the context and chat history provided. If the context is not relevant to the user's query, politely state that you do not have the required information.\n",
    "\n",
    "    Chat History: {chat_history}\n",
    "    \n",
    "    Context: {combined_context}\n",
    "    \n",
    "    Question: {user_query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Update chat memory\n",
    "    memory.save_context({\"input\": user_query}, {\"output\": response})\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Server-Side RAG Assistant 🤖\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        selected_embed = gr.Dropdown(choices=list(embed_methods.keys()), label=\"Select Embedding Method\")\n",
    "        file_uploader = gr.File(label=\"Upload a PDF\")\n",
    "        upload_button = gr.Button(\"Upload\")\n",
    "    \n",
    "    upload_output = gr.Textbox(label=\"Upload Status\")\n",
    "    upload_button.click(process_upload, inputs=[file_uploader, selected_embed], outputs=upload_output)\n",
    "    \n",
    "    \n",
    "    chatbot = gr.ChatInterface(fn=query_rag_pipeline, title=\"Chatbot Assistant\", type=\"messages\")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623cab3-e061-4ef5-b352-90899060d747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
