{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dec4134-34f9-47d1-9ea3-a6e9791ab6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import PyMuPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import pymupdf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56950969-29d9-43b8-aca8-495d545ebed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knowledge_base/3GPP', 'knowledge_base/articles']\n"
     ]
    }
   ],
   "source": [
    "# PDF dosyasını yükleme\n",
    "pdf_folders_path =glob.glob(\"knowledge_base/*\")\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "print(pdf_folders_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab78e57-bbc3-4f5f-9508-8dc3653a3744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: knowledge_base/3GPP\n",
      "Processing folder: knowledge_base/articles\n"
     ]
    }
   ],
   "source": [
    "chunked_documents = []\n",
    "\n",
    "for pdf_folder in pdf_folders_path:\n",
    "    \n",
    "    print(f\"Processing folder: {pdf_folder}\")\n",
    "\n",
    "    loader = DirectoryLoader(pdf_folder, glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "    folder_docs = loader.load()\n",
    "\n",
    "\n",
    "    pdf_files = glob.glob(os.path.join(pdf_folder, \"*.pdf\"))\n",
    "\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        # PDF dosyasını aç\n",
    "        pdf_open = pymupdf.open(pdf_path)\n",
    "        \n",
    "        # Table of Contents (TOC) al\n",
    "        toc = pdf_open.get_toc()\n",
    "\n",
    "        for i, item in enumerate(toc):\n",
    "            heading = item[1]\n",
    "            start_page = item[2]\n",
    "\n",
    "            if i + 1 < len(toc):\n",
    "                end_page = toc[i + 1][2] - 1\n",
    "            else:\n",
    "                end_page = pdf_open.page_count  # Son başlıksa PDF'in son sayfasına kadar\n",
    "    \n",
    "            # Sonraki başlığın sayfasına kadar olan kısmı almak\n",
    "            if i + 1 < len(toc):\n",
    "                end_page = toc[i + 1][2] - 1\n",
    "            else:\n",
    "                end_page = pdf_open.page_count -  1   # Son başlıksa PDF'in son sayfasına kadar\n",
    "\n",
    "            # Metni birleştirerek chunk oluştur\n",
    "            chunk_text = \"\"\n",
    "            for page_num in range(start_page, end_page):  # PyMuPDF için 0-index\n",
    "                chunk_text += pdf_open[page_num].get_text()\n",
    "\n",
    "        # İlk chunk'ları oluştur ve listeye ekle\n",
    "            chunked_documents.append(\n",
    "                Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata={\"heading\": heading, \"start_page\": start_page, \"end_page\": end_page}\n",
    "                )\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e4a4db-eecc-4968-9a7d-112c03379384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CharacterTextSplitter kullanarak ek parçalama\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# TOC'ye göre bölünmüş metinleri tekrar split ediyoruz\n",
    "final_chunks = text_splitter.split_documents(chunked_documents)\n",
    "\n",
    "# Çıktıyı kontrol etmek için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16171b3b-0384-4f1b-8ffc-68187f3bc1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1072"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12492f2-8c7b-472c-a901-7509878c8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "# Create our Chroma vectorstore!\n",
    "db_name = \"vector-db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511ae1d4-a206-4713-8931-d5a9b17c07a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 1416 documents\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embeddings = FastEmbedEmbeddings(device=\"cpu\")\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create our Chroma vectorstore!\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=final_chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8f63cc-7167-4bd7-b857-7876da623590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from tiktoken import get_encoding\n",
    "from langchain.schema import HumanMessage\n",
    "#from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d83870-3708-47da-9b45-41e68240e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert evaluator for RAG systems. Evaluate the response using the following criteria:\n",
    "\n",
    "1. **Groundedness**: \n",
    "   - Does the response rely on and accurately use the provided context? \n",
    "   - A high score (close to 1) means the response is fully grounded in the given context, while a low score (close to 0) indicates that the response includes information that is not present or contradicts the context. Your score should be between 0 and 1. Such as 0.45.\n",
    "\n",
    "2. **Answer Relevance**: \n",
    "   - Is the response relevant to and directly answering the question?\n",
    "   - A high score (close to 1) means the response is precise, well-aligned with the question, and provides a clear answer. A low score (close to 0) indicates the response is irrelevant or off-topic.Your score should be between 0 and 1. Such as 0.45.\n",
    "\n",
    "3. **Context Relevance**: \n",
    "   - Does the provided context contain information that is useful and directly related to answering the question?\n",
    "   - A high score (close to 1) means the context fully supports answering the question, while a low score (close to 0) means the context is unrelated or insufficient for the question.Your score should be between 0 and 1. Such as 0.45.\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "Evaluate the following inputs:\n",
    "\n",
    "**Context**:  \n",
    "{context}\n",
    "\n",
    "**Question**:  \n",
    "{question}\n",
    "\n",
    "**Response**:  \n",
    "{response}\n",
    "\n",
    "**Ground Truth**:  \n",
    "{ground_truth}\n",
    "\n",
    "------\n",
    "\n",
    "Provide a float score between 0 and 1 such as 0.534 for each criterion along with a short justification for your score. The output should follow this format:\n",
    "\n",
    "Groundedness: X/1  \n",
    "Explanation: [Your explanation]\n",
    "\n",
    "Answer Relevance: X/1 \n",
    "Explanation: [Your explanation]\n",
    "\n",
    "Context Relevance: X/1  \n",
    "Explanation: [Your explanation]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "172cfc31-49bd-441f-8a63-8e8f7ca36a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"Can you categorize large Telecom model use cases?\",\n",
    "        \"answer\": \n",
    "            \"1. Network Management and Optimization:\\n\"\n",
    "            \"- Qiming Network Model: Supports network planning, maintenance, monitoring, troubleshooting, and performance optimization. Enhances real-time decision-making processes.\\n\"\n",
    "            \"- Network Automation & Intent-Based Management: Translates user intents into machine-readable commands to automate network operations.\\n\\n\"\n",
    "            \n",
    "            \"2. Physical and MAC Layer Design:\\n\"\n",
    "            \"- Wireless Signal Analysis: Optimizes tasks like spectrum management and interference detection using time-series data.\\n\\n\"\n",
    "            \n",
    "            \"3. Data Management and Security:\\n\"\n",
    "            \"- Fraud Detection & Security: Utilizes transfer learning for anomaly detection to identify fraudulent activities.\\n\"\n",
    "            \"- Data Compliance: Ensures data processing workflows align with regulations like GDPR.\\n\\n\"\n",
    "            \n",
    "            \"4. Vertical Applications:\\n\"\n",
    "            \"- Healthcare: Supports remote patient monitoring and predictive diagnostics.\\n\"\n",
    "            \"- Smart Cities: Applied in traffic management, energy optimization, and public safety initiatives.\\n\\n\"\n",
    "            \n",
    "            \"5. Next-Generation Networks (5G and Beyond):\\n\"\n",
    "            \"- Network Slicing & Edge Computing: Optimizes resource allocation to deliver more flexible services.\\n\"\n",
    "            \"- Telecom Co-Pilots: Develops intelligent assistants for operational support.\"\n",
    "        \n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c24bea4a-c9c7-4429-92aa-44a86dd2207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://8d50847a12ae6b33c9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8d50847a12ae6b33c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import gradio as gr\n",
    "\n",
    "# OLLAMA API URL\n",
    "url = \"http://45.145.22.22:11434/api/chat\"\n",
    "\n",
    "# Başlıklar\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Retriever - VectorStore\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# API'den yanıt ve değerlendirme almak için fonksiyon tanımlama\n",
    "def ask_and_evaluate(user_question, ground_truth):\n",
    "    # similarity_search çıktısını al\n",
    "    retrieved_contexts = vectorstore.similarity_search(user_question, k=10)\n",
    "\n",
    "    # Belgelerin içeriğini birleştir\n",
    "    combined_context = \" \".join([doc.page_content for doc in retrieved_contexts])\n",
    "\n",
    "    # API ile iletişim için mesajı hazırla\n",
    "    input_message = {\n",
    "        \"model\": \"llama3.2\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a telecom assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {combined_context}\\n\\nQuestion: {user_question}\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # API'ye istek gönder ve yanıtı oku\n",
    "    response = requests.post(url, json=input_message, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        combined_response = \"\"\n",
    "        for line in response.text.strip().split(\"\\n\"):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                content = data['message']['content']\n",
    "                combined_response += content\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON Decode Hatası: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        return f\"API Hatası: {response.status_code} - {response.text}\", \"Evaluation Error\"\n",
    "\n",
    "    # Değerlendirme prompt'unu oluştur\n",
    "    grader_prompt = GRADER_PROMPT_TEMPLATE.format(\n",
    "        context=combined_context,\n",
    "        question=user_question,\n",
    "        response=combined_response,\n",
    "        ground_truth=ground_truth\n",
    "    )\n",
    "\n",
    "    # Değerlendirme için API'yi çağır\n",
    "    evaluation_response = requests.post(url, json={\"model\": \"llama3.2\", \"messages\": [{\"role\": \"user\", \"content\": grader_prompt}]}, headers=headers)\n",
    "\n",
    "    if evaluation_response.status_code == 200:\n",
    "        eval_combined_response = \"\"\n",
    "        for line in evaluation_response.text.strip().split(\"\\n\"):\n",
    "            try:\n",
    "                eval_data = json.loads(line)\n",
    "                eval_content = eval_data['message']['content']\n",
    "                eval_combined_response += eval_content\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Değerlendirme JSON Decode Hatası: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        eval_combined_response = f\"Değerlendirme API Hatası: {evaluation_response.status_code} - {evaluation_response.text}\"\n",
    "\n",
    "    return combined_response, eval_combined_response\n",
    "\n",
    "# Gradio arayüzü\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Telecom Assistant QA and Evaluation\")\n",
    "    question_input = gr.Textbox(label=\"Soru\", placeholder=\"Sorunuzu buraya yazın...\")\n",
    "    ground_truth_input = gr.Textbox(label=\"Ground Truth\", placeholder=\"Enter the expected ground truth...\")\n",
    "    submit_btn = gr.Button(\"Sor ve Değerlendir\")\n",
    "\n",
    "    response_output = gr.Textbox(label=\"Model Yanıtı\")\n",
    "    evaluation_output = gr.Textbox(label=\"Değerlendirme Sonucu\")\n",
    "\n",
    "    submit_btn.click(ask_and_evaluate, inputs=[question_input, ground_truth_input], outputs=[response_output, evaluation_output])\n",
    "\n",
    "# Arayüzü başlatma\n",
    "demo.launch(share= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ede4c7-5d93-4df3-9d3e-3ed30d4f70eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ask_question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m iface \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(\n\u001b[0;32m----> 3\u001b[0m     fn\u001b[38;5;241m=\u001b[39mask_question,\n\u001b[1;32m      4\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mTextbox(lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, placeholder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBir soru girin...\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m     outputs\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mTextbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYanıt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelecom Assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelekom özelinde sorularınızı sorabilirsiniz.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Uygulamayı başlat\u001b[39;00m\n\u001b[1;32m     13\u001b[0m iface\u001b[38;5;241m.\u001b[39mlaunch(share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ask_question' is not defined"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "iface = gr.Interface(\n",
    "    fn=ask_question,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Bir soru girin...\"),\n",
    "    outputs=gr.Textbox(label=\"Yanıt\"),\n",
    "    title=\"Telecom Assistant\",\n",
    "    description=\"Telekom özelinde sorularınızı sorabilirsiniz.\"\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Uygulamayı başlat\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a64aa11a-b934-4af6-8a51-c1ed324ac256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:Can you categorize large Telecom model use cases?\n",
      "Response:The use cases for Large Telecom Models can be categorized into the following:\n",
      "\n",
      "**Application Enhancement**\n",
      "\n",
      "1. Improving network capabilities by adding new functionalities or improving existing ones.\n",
      "2. Enhancing mobile network operations through automation and optimization.\n",
      "\n",
      "**Network Operations and Maintenance**\n",
      "\n",
      "3. Automating network configuration generation.\n",
      "4. Reducing manual effort in network management.\n",
      "5. Improving network performance, security, and compliance.\n",
      "\n",
      "**Customer Service and Business Processes**\n",
      "\n",
      "6. Developing network-related software components.\n",
      "7. Generating troubleshooting solutions.\n",
      "8. Providing zero-shot image classification capabilities for complicated signal transmission environments.\n",
      "\n",
      "**Policy Generation and Intent-Based Application Management**\n",
      "\n",
      "9. Leveraging LLMs for policy generation.\n",
      "10. Automating intent-based application management.\n",
      "\n",
      "**Troubleshooting and Fault Diagnosis**\n",
      "\n",
      "11. Diagnosing faults in wireless networks.\n",
      "12. Providing automated code refactoring and design.\n",
      "\n",
      "Overall, Large Telecom Models are being used to improve the intelligence of network operation and maintenance, customer service, business processes, and policy generation, as well as to automate tasks such as network configuration generation, troubleshooting, and fault diagnosis.\n",
      "Ground Truth:1. Network Management and Optimization:\n",
      "- Qiming Network Model: Supports network planning, maintenance, monitoring, troubleshooting, and performance optimization. Enhances real-time decision-making processes.\n",
      "- Network Automation & Intent-Based Management: Translates user intents into machine-readable commands to automate network operations.\n",
      "\n",
      "2. Physical and MAC Layer Design:\n",
      "- Wireless Signal Analysis: Optimizes tasks like spectrum management and interference detection using time-series data.\n",
      "\n",
      "3. Data Management and Security:\n",
      "- Fraud Detection & Security: Utilizes transfer learning for anomaly detection to identify fraudulent activities.\n",
      "- Data Compliance: Ensures data processing workflows align with regulations like GDPR.\n",
      "\n",
      "4. Vertical Applications:\n",
      "- Healthcare: Supports remote patient monitoring and predictive diagnostics.\n",
      "- Smart Cities: Applied in traffic management, energy optimization, and public safety initiatives.\n",
      "\n",
      "5. Next-Generation Networks (5G and Beyond):\n",
      "- Network Slicing & Edge Computing: Optimizes resource allocation to deliver more flexible services.\n",
      "- Telecom Co-Pilots: Develops intelligent assistants for operational support.\n",
      "Context:Here are the float scores with justifications for each criterion:\n",
      "\n",
      "**Network Management and Optimization**\n",
      "\n",
      "Groundedness: 0.8/1\n",
      "Explanation: The Qiming Network Model is a concrete example of a Large Telecom Model, and its applications in network planning, maintenance, monitoring, troubleshooting, and performance optimization are well-defined and practical.\n",
      "\n",
      "Answer Relevance: 0.9/1\n",
      "Explanation: The text directly discusses the use cases for Large Telecom Models in network management and optimization, making it highly relevant to this criterion.\n",
      "\n",
      "Context Relevance: 0.9/1\n",
      "Explanation: The context of the text is clearly related to Large Telecom Models and their applications in telecommunications, making it easy to understand and apply the information.\n",
      "\n",
      "**Network Automation & Intent-Based Management**\n",
      "\n",
      "Groundedness: 0.7/1\n",
      "Explanation: While the concept of network automation and intent-based management is mentioned, it is not a specific example of a Large Telecom Model application. The text would benefit from more concrete details or examples.\n",
      "\n",
      "Answer Relevance: 0.8/1\n",
      "Explanation: Although not directly discussed, the text mentions \"network configuration generation\" as an application of Large Telecom Models, which is related to network automation and intent-based management.\n",
      "\n",
      "Context Relevance: 0.8/1\n",
      "Explanation: The context is still relevant to Large Telecom Models and their applications in telecommunications, although the specific example could be more concrete.\n",
      "\n",
      "**Physical and MAC Layer Design**\n",
      "\n",
      "Groundedness: 0.6/1\n",
      "Explanation: While the text mentions \"wireless signal analysis\" as an application of Large Telecom Models, it is a relatively narrow example compared to other areas. More examples would strengthen this criterion.\n",
      "\n",
      "Answer Relevance: 0.7/1\n",
      "Explanation: Although not directly discussed, the concept of large-scale wireless networks is relevant to Physical and MAC Layer Design, although the text does not provide specific details.\n",
      "\n",
      "Context Relevance: 0.7/1\n",
      "Explanation: The context is still somewhat related to Large Telecom Models and their applications in telecommunications, but could be more explicit about the relevance to Physical and MAC Layer Design.\n",
      "\n",
      "**Data Management and Security**\n",
      "\n",
      "Groundedness: 0.9/1\n",
      "Explanation: The text provides concrete examples of Large Telecom Models being applied to data management and security, such as fraud detection and data compliance.\n",
      "\n",
      "Answer Relevance: 0.9/1\n",
      "Explanation: The text directly discusses the use cases for Large Telecom Models in data management and security, making it highly relevant to this criterion.\n",
      "\n",
      "Context Relevance: 0.9/1\n",
      "Explanation: The context is clearly related to Large Telecom Models and their applications in telecommunications, including data management and security.\n",
      "\n",
      "**Vertical Applications**\n",
      "\n",
      "Groundedness: 0.8/1\n",
      "Explanation: While the text mentions \"healthcare\" and \"smart cities\" as vertical applications of Large Telecom Models, it would benefit from more concrete examples or details.\n",
      "\n",
      "Answer Relevance: 0.8/1\n",
      "Explanation: The text directly discusses the use cases for Large Telecom Models in vertical applications, making it highly relevant to this criterion.\n",
      "\n",
      "Context Relevance: 0.8/1\n",
      "Explanation: The context is still relevant to Large Telecom Models and their applications in telecommunications, including vertical applications.\n",
      "\n",
      "**Next-Generation Networks (5G and Beyond)**\n",
      "\n",
      "Groundedness: 0.6/1\n",
      "Explanation: While the text mentions \"network slicing\" and \"edge computing\" as applications of Large Telecom Models, it would benefit from more concrete examples or details.\n",
      "\n",
      "Answer Relevance: 0.7/1\n",
      "Explanation: The text directly discusses the use cases for Large Telecom Models in next-generation networks (5G and beyond), making it relevant to this criterion.\n",
      "\n",
      "Context Relevance: 0.7/1\n",
      "Explanation: The context is still somewhat related to Large Telecom Models and their applications in telecommunications, although the specific examples could be more concrete.\n",
      "\n",
      "**Telecom Co-Pilots**\n",
      "\n",
      "Groundedness: 0.5/1\n",
      "Explanation: While the text mentions \"telecom co-pilots\" as an application of Large Telecom Models, it is a relatively high-level concept that would benefit from more concrete details or examples.\n",
      "\n",
      "Answer Relevance: 0.6/1\n",
      "Explanation: The text directly discusses the use cases for Large Telecom Models in telecom co-pilots, making it somewhat relevant to this criterion.\n",
      "\n",
      "Context Relevance: 0.6/1\n",
      "Explanation: The context is still somewhat related to Large Telecom Models and their applications in telecommunications, although the specific examples could be more concrete.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(f\"Question:{question}\")\n",
    "    print(f\"Response:{combined_response}\")\n",
    "    print(f\"Ground Truth:{ground_truth}\")\n",
    "    print(f\"Context:{eval_combined_response}\")\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7dd9c-22e5-4b5b-9db5-48faf5e5d80e",
   "metadata": {},
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Model ve Tokenizer'ı yükle\n",
    "model_name = \"/mnt/storage/Llama-3.3-70B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Retriever - VectorStore\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Sonuçları saklamak için bir liste\n",
    "evaluation_results = []\n",
    "\n",
    "# Her bir input üzerinde işlem yapma\n",
    "for qa_pair in questions_answers:\n",
    "    question = qa_pair[\"question\"]\n",
    "    ground_truth = qa_pair[\"answer\"]\n",
    "\n",
    "    # similarity_search çıktısını al\n",
    "    retrieved_contexts = vectorstore.similarity_search(question, k=10)\n",
    "    \n",
    "    # Belgelerin içeriğini birleştir\n",
    "    combined_context = \" \".join([doc.page_content for doc in retrieved_contexts])\n",
    "\n",
    "    # Input mesajını hazırlayın\n",
    "    input_text = f\"Context: {combined_context}\\n\\nQuestion: {question}\"\n",
    "\n",
    "    # Input verisini token'lara dönüştür\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Modelden yanıt al\n",
    "    outputs = model.generate(**inputs, max_length=512, num_return_sequences=1)\n",
    "\n",
    "    # Yanıtı çözümle\n",
    "    model_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Değerlendirme prompt'unu oluştur\n",
    "    grader_prompt = GRADER_PROMPT_TEMPLATE.format(\n",
    "        context=\" \".join([doc.page_content for doc in retrieved_contexts]),\n",
    "        question=question,\n",
    "        response=model_response,\n",
    "        ground_truth=ground_truth\n",
    "    )\n",
    "\n",
    "    # Değerlendirme için modelden yanıt al\n",
    "    evaluation_inputs = tokenizer(grader_prompt, return_tensors=\"pt\")\n",
    "    evaluation_outputs = model.generate(**evaluation_inputs, max_length=512, num_return_sequences=1)\n",
    "\n",
    "    # Değerlendirme yanıtını çözümle\n",
    "    evaluation_result = tokenizer.decode(evaluation_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Sonuçları kaydet\n",
    "    evaluation_results.append({\n",
    "        \"query\": question,\n",
    "        \"response\": model_response,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"evaluation\": evaluation_result\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb5bab-cfce-4a5d-8838-1c0db47e40a8",
   "metadata": {},
   "source": [
    "# Memory\n",
    "#memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# Retriever - VectorStore \n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Conversational Retrieval Chain\n",
    "#conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)\n",
    "\n",
    "llm = ChatOllama(\n",
    "                 model = \"llama3.2\")\n",
    "# Sonuçları saklamak için bir liste\n",
    "evaluation_results = []\n",
    "\n",
    "# Her bir input üzerinde işlem yapma\n",
    "\n",
    "for qa_pair in questions_answers:\n",
    "    question = qa_pair[\"question\"]\n",
    "    ground_truth = qa_pair[\"answer\"]\n",
    "    # similarity_search çıktısını stringe dönüştür\n",
    "    retrieved_contexts = vectorstore.similarity_search(question, k=10)\n",
    "    combined_context = \" \".join([doc.page_content for doc in retrieved_contexts])\n",
    "\n",
    "    \n",
    "    input_message = HumanMessage(content=f\"Context: {combined_context}\\n\\nQuestion: {question}\")\n",
    "    response = llm.invoke([input_message])\n",
    "    # Değerlendirme prompt'unu hazırlama\n",
    "    grader_prompt = GRADER_PROMPT_TEMPLATE.format(\n",
    "                    context=retrieved_contexts,\n",
    "                    question=question,\n",
    "                    response=response.content,\n",
    "                    ground_truth=ground_truth)\n",
    "        \n",
    "    evaluation_result = llm.invoke(grader_prompt)\n",
    "\n",
    "    evaluation_results.append({\n",
    "        \"query\": question,\n",
    "        \"response\": response,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"evaluation\": evaluation_result.content\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe036ae9-c2d1-417f-9eaf-05f656ec6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9fae0f-36ee-46b9-b894-33985588871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "#memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# Retriever - VectorStore \n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Conversational Retrieval Chain\n",
    "#conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)\n",
    "\n",
    "llm = ChatOllama(\n",
    "                 model = \"llama3.2\")\n",
    "# Sonuçları saklamak için bir liste\n",
    "evaluation_results = []\n",
    "\n",
    "# Her bir input üzerinde işlem yapma\n",
    "\n",
    "for qa_pair in questions_answers:\n",
    "    question = qa_pair[\"question\"]\n",
    "    ground_truth = qa_pair[\"answer\"]\n",
    "    # similarity_search çıktısını stringe dönüştür\n",
    "    retrieved_contexts = vectorstore.similarity_search(question, k=10)\n",
    "    combined_context = \" \".join([doc.page_content for doc in retrieved_contexts])\n",
    "\n",
    "    \n",
    "    input_message = HumanMessage(content=f\"Context: {combined_context}\\n\\nQuestion: {question}\")\n",
    "    response = llm.invoke([input_message])\n",
    "    # Değerlendirme prompt'unu hazırlama\n",
    "    grader_prompt = GRADER_PROMPT_TEMPLATE.format(\n",
    "                    context=retrieved_contexts,\n",
    "                    question=question,\n",
    "                    response=response.content,\n",
    "                    ground_truth=ground_truth)\n",
    "        \n",
    "    evaluation_result = llm.invoke(grader_prompt)\n",
    "\n",
    "    evaluation_results.append({\n",
    "        \"query\": question,\n",
    "        \"response\": response,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"evaluation\": evaluation_result.content\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab96a837-9411-4add-a455-25f378547223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:What is the significance of TreselectionNR, and how does it impact cell reselection?\n",
      "Response:content=\"T-ReselectionNR (also known as treselection) is a parameter used to determine when a UE (User Equipment) should perform reselection to another cell. It is part of the 5G New Radio (NR) protocol.\\n\\nIn the context of NR, treselection refers to the process by which the UE evaluates new cells for reselection based on specific criteria, such as signal strength and priority. The T-ReselectionNR parameter specifies how quickly the UE should perform this evaluation after detecting a change in cell conditions or when the UE is experiencing a significant drop in signal quality.\\n\\nThe significance of treselectionNR lies in its impact on cell reselection:\\n\\n1. **Improved network performance**: By performing reselection more frequently, the UE can detect and switch to better-quality cells, leading to improved overall network performance.\\n2. **Reduced handovers**: Frequent reselections can reduce the need for more invasive handover procedures, such as RRC Release or UARFCN change, which can cause additional latency and disruption.\\n3. **Increased cell coverage**: By quickly detecting and switching to better-quality cells, the UE can maintain a stable connection even when the primary cell's signal strength degrades.\\n\\nThe T-ReselectionNR parameter is set based on the minimum related performance requirements specified in TS 38.133 [8]. The value of this parameter determines how quickly the UE will perform reselection after detecting a change in cell conditions or when experiencing a significant drop in signal quality.\\n\\nTypically, the T-ReselectionNR parameter is set to a relatively low value (e.g., 100 ms) to ensure that the UE performs frequent reselections and maintains a stable connection. This allows the network to adapt quickly to changes in the environment and provides better overall performance.\" additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-01-31T02:53:09.153063824Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2184316643, 'load_duration': 31682590, 'prompt_eval_count': 2048, 'prompt_eval_duration': 159000000, 'eval_count': 361, 'eval_duration': 1990000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d82e2351-3a52-41cf-a8cb-abb3f56707ca-0' usage_metadata={'input_tokens': 2048, 'output_tokens': 361, 'total_tokens': 2409}\n",
      "Ground Truth:TreselectionNR is a timer that defines the duration a target cell must meet reselection criteria before the UE reselects. It ensures stability by preventing rapid and unnecessary reselection events.\n",
      "Context:Here are the scores with justifications for each criterion:\n",
      "\n",
      "**TreselectionNR**: 0.9/1\n",
      "Justification: TreselectionNR is a critical parameter in 5G NR, and its value significantly impacts cell reselection. A high score reflects its importance in determining when a UE should perform reselection.\n",
      "\n",
      "Groundedness: 0.9/1  \n",
      "Explanation: TreselectionNR is a well-defined parameter in the 5G NR protocol, and its value is carefully specified to ensure optimal network performance.\n",
      "\n",
      "Answer Relevance: 0.8/1  \n",
      "Explanation: While treselectionNR is an important parameter, it may not be directly relevant to every question or context. However, its significance in 5G NR makes it a relevant topic for discussion.\n",
      "\n",
      "Context Relevance: 0.7/1  \n",
      "Explanation: TreselectionNR is more relevant in the context of 5G NR and mobile networks than in general knowledge domains. Its relevance can vary depending on the specific question or context.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    print(f\"Question:{question}\")\n",
    "    print(f\"Response:{response}\")\n",
    "    print(f\"Ground Truth:{ground_truth}\")\n",
    "    print(f\"Context:{evaluation_result.content}\")\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ae4b8d-a3f7-4c74-b20c-3823dcbd49c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ollama\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m Ollama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a joke\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/llms.py:387\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    385\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 387\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    388\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    389\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    390\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    391\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    392\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    393\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    394\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    399\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/llms.py:760\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    754\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    758\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    759\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/llms.py:963\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    950\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    951\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     ]\n\u001b[0;32m--> 963\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[1;32m    964\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    965\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_core/language_models/llms.py:784\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    776\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    781\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 784\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    785\u001b[0m                 prompts,\n\u001b[1;32m    786\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    787\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[1;32m    788\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    789\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    790\u001b[0m             )\n\u001b[1;32m    791\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    793\u001b[0m         )\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_community/llms/ollama.py:437\u001b[0m, in \u001b[0;36mOllama._generate\u001b[0;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m--> 437\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_stream_with_aggregation(\n\u001b[1;32m    438\u001b[0m         prompt,\n\u001b[1;32m    439\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    440\u001b[0m         images\u001b[38;5;241m=\u001b[39mimages,\n\u001b[1;32m    441\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    442\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_community/llms/ollama.py:349\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    342\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    347\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[1;32m    348\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[1;32m    351\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/langchain_community/llms/ollama.py:194\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[0;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    188\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    192\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    193\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[1;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[1;32m    196\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    197\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    199\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[1;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[1;32m    871\u001b[0m ):\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/utils.py:572\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[0;34m(iterator, r)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    571\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    573\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/response.py:1206\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_chunk_length()\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1208\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/response.py:1125\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1125\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9554c-2269-4044-a89c-60d793096b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6008c6e-3004-4c7e-bfab-4bf838d316ca",
   "metadata": {},
   "source": [
    "# TABLE EXTRACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37d210-b334-49b8-9870-7e192427bc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c30208e-e02a-4f59-8bfe-5444ab5ff32e",
   "metadata": {},
   "source": [
    "# IMAGE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5354dad2-58ea-4f21-aeba-f0699cc8fb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file example/About-GSM/36201-i00.pdf\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_text() got an unexpected keyword argument 'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdf_folders_path:\n\u001b[1;32m     14\u001b[0m     loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(pdf, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**/*.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, loader_cls\u001b[38;5;241m=\u001b[39mPyMuPDFLoader, loader_kwargs\u001b[38;5;241m=\u001b[39mtext_loader_kwargs)\n\u001b[0;32m---> 15\u001b[0m     folder_docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pdf_ \u001b[38;5;129;01min\u001b[39;00m folder_docs:\n\u001b[1;32m     18\u001b[0m         open_pdf \u001b[38;5;241m=\u001b[39m pymupdf\u001b[38;5;241m.\u001b[39mopen(pdf_)\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:195\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[0;32m--> 195\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_file(i, p, pbar)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[1;32m    198\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:233\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[0;34m(self, item, path, pbar)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:223\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[0;34m(self, item, path, pbar)\u001b[0m\n\u001b[1;32m    221\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_cls(\u001b[38;5;28mstr\u001b[39m(item), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_kwargs)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:454\u001b[0m, in \u001b[0;36mPyMuPDFLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load()\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:448\u001b[0m, in \u001b[0;36mPyMuPDFLoader._lazy_load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     blob \u001b[38;5;241m=\u001b[39m Blob\u001b[38;5;241m.\u001b[39mfrom_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/parsers/pdf.py:280\u001b[0m, in \u001b[0;36mPyMuPDFParser.lazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     doc \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen(stream\u001b[38;5;241m=\u001b[39mfile_path, filetype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/parsers/pdf.py:282\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     doc \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen(stream\u001b[38;5;241m=\u001b[39mfile_path, filetype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m [\n\u001b[1;32m    281\u001b[0m     Document(\n\u001b[0;32m--> 282\u001b[0m         page_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    283\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_metadata(doc, page, blob),\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m doc\n\u001b[1;32m    286\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.11/site-packages/langchain_community/document_loaders/parsers/pdf.py:295\u001b[0m, in \u001b[0;36mPyMuPDFParser._get_page_content\u001b[0;34m(self, doc, page, blob)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_page_content\u001b[39m(\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m, doc: fitz\u001b[38;5;241m.\u001b[39mfitz\u001b[38;5;241m.\u001b[39mDocument, page: fitz\u001b[38;5;241m.\u001b[39mfitz\u001b[38;5;241m.\u001b[39mPage, blob: Blob\n\u001b[1;32m    290\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    Get the text of the page using PyMuPDF and RapidOCR and issue a warning\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    if it is empty.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_images_from_page(\n\u001b[1;32m    296\u001b[0m         doc, page\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content:\n\u001b[1;32m    300\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Empty content on page \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of document \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: get_text() got an unexpected keyword argument 'encoding'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chunked_documents = []\n",
    "\n",
    "for pdf in pdf_folders_path:\n",
    "    loader = DirectoryLoader(pdf, glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "\n",
    "    for pdf_ in folder_docs:\n",
    "        open_pdf = pymupdf.open(pdf_)\n",
    "        toc = open_pdf.get_toc()\n",
    "        for i, item in enumerate(toc):\n",
    "            heading = item[1]\n",
    "            start_page = item[2]\n",
    "\n",
    "            if i + 1 < len(toc):\n",
    "                end_page = toc[i+1][2] - 1\n",
    "            else:\n",
    "                end_page = pdf.page_count\n",
    "\n",
    "            chunk_text = \"\"\n",
    "\n",
    "            for page_num in range(start_page -1, end_page):\n",
    "                chunk_text += open_pdf[page_num].get_text()\n",
    "\n",
    "            chunked_documents.append(\n",
    "                Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata={\"heading\": heading, \"start_page\": start_page, \"end_page\": end_page}\n",
    "                )\n",
    "            )\n",
    "        open_pdf.close()        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "pdf = pymupdf.open(pdf_path)\n",
    "\n",
    "# TOC'yi al\n",
    "toc = pdf.get_toc()\n",
    "\n",
    "# LangChain için yeni Document objeleri oluşturma\n",
    "chunked_documents = []\n",
    "\n",
    "for i, item in enumerate(toc):\n",
    "    heading = item[1]\n",
    "    start_page = item[2]\n",
    "    \n",
    "    # Sonraki başlığın sayfasına kadar olan kısmı almak\n",
    "    if i + 1 < len(toc):\n",
    "        end_page = toc[i + 1][2] - 1\n",
    "    else:\n",
    "        end_page = pdf.page_count  # Son başlıksa PDF'in son sayfasına kadar\n",
    "\n",
    "    # Metni birleştirerek chunk oluştur\n",
    "    chunk_text = \"\"\n",
    "    for page_num in range(start_page - 1, end_page):  # PyMuPDF için 0-index\n",
    "        chunk_text += pdf[page_num].get_text()\n",
    "\n",
    "    # İlk chunk'ları oluştur ve listeye ekle\n",
    "    chunked_documents.append(\n",
    "        Document(\n",
    "            page_content=chunk_text,\n",
    "            metadata={\"heading\": heading, \"start_page\": start_page, \"end_page\": end_page}\n",
    "        )\n",
    "    )\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5565d817-6b09-49af-afb5-8783f9ac089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "# Create our Chroma vectorstore!\n",
    "db_name = \"vector-db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e1035-a09a-478f-bc17-3bd04176d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create our Chroma vectorstore!\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=final_chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73580b7e-4b85-445a-9ddd-19755fc6bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from tiktoken import get_encoding\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LLM için OpenAI GPT 4O modelini tanımlıyoruz\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "llmOpenAI = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Memory\n",
    "#memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# Retriever - VectorStore \n",
    "retriever = vectorstore\n",
    "\n",
    "# Conversational Retrieval Chain\n",
    "#conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)\n",
    "\n",
    "# Değerlendirme prompt şablonu\n",
    "GRADER_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert evaluator for RAG systems. Evaluate the response using the following criteria:\n",
    "\n",
    "1. **Groundedness**: \n",
    "   - Does the response rely on and accurately use the provided context? \n",
    "   - A high score (close to 1) means the response is fully grounded in the given context, while a low score (close to 0) indicates that the response includes information that is not present or contradicts the context. Your score should be between 0 and 1. Such as 0.45.\n",
    "\n",
    "2. **Answer Relevance**: \n",
    "   - Is the response relevant to and directly answering the question?\n",
    "   - A high score (close to 1) means the response is precise, well-aligned with the question, and provides a clear answer. A low score (close to 0) indicates the response is irrelevant or off-topic.Your score should be between 0 and 1. Such as 0.45.\n",
    "\n",
    "3. **Context Relevance**: \n",
    "   - Does the provided context contain information that is useful and directly related to answering the question?\n",
    "   - A high score (close to 1) means the context fully supports answering the question, while a low score (close to 0) means the context is unrelated or insufficient for the question.Your score should be between 0 and 1. Such as 0.45.\n",
    "\n",
    "4. **Accuracy Compared to Ground Truth**:\n",
    "   - How close is the response to the ground truth answer provided? \n",
    "   - A high score (close to 1) means the response matches the ground truth closely, while a low score (close to 0) indicates significant deviations.Your score should be between 0 and 1. Such as 0.45.\n",
    "\n",
    "---\n",
    "\n",
    "Evaluate the following inputs:\n",
    "\n",
    "**Context**:  \n",
    "{context}\n",
    "\n",
    "**Question**:  \n",
    "{question}\n",
    "\n",
    "**Response**:  \n",
    "{response}\n",
    "\n",
    "**Ground Truth**:  \n",
    "{ground_truth}\n",
    "\n",
    "---\n",
    "\n",
    "Provide a float score between 0 and 1 such as 0.534 for each criterion along with a short justification for your score. The output should follow this format:\n",
    "\n",
    "Groundedness: X/1  \n",
    "Explanation: [Your explanation]\n",
    "\n",
    "Answer Relevance: X/1 \n",
    "Explanation: [Your explanation]\n",
    "\n",
    "Context Relevance: X/1  \n",
    "Explanation: [Your explanation]\n",
    "\n",
    "Accuracy Compared to Ground Truth: X/1  \n",
    "Explanation: [Your explanation]\n",
    "\"\"\"\n",
    "\n",
    "MAX_TOKENS = 4096\n",
    "\n",
    "def truncate_to_token_limit(text, token_limit=MAX_TOKENS, encoding_name=\"cl100k_base\"):\n",
    "    encoding = get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    if len(tokens) > token_limit:\n",
    "        truncated_tokens = tokens[:token_limit]\n",
    "        return encoding.decode(truncated_tokens)\n",
    "    return text\n",
    "\n",
    "\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"What are the differences between the RRC_IDLE and RRC_INACTIVE states in terms of UE behavior?\",\n",
    "        \"answer\": \"In RRC_IDLE, the UE camps on a cell, monitors system information, and performs paging while not connected. In RRC_INACTIVE, the UE maintains a context with the network but does not actively transmit or receive, allowing faster resumption of connection. Both states share procedures like PLMN selection and cell reselection.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE determine a 'suitable cell' for camping? Which parameters does it evaluate?\",\n",
    "        \"answer\": \"A 'suitable cell' is determined based on criteria like signal strength (Srxlev), signal quality (Squal), and whether the cell belongs to the selected PLMN or SNPN. The cell must not be barred or restricted.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the procedures the UE follows during PLMN selection in both automatic and manual modes?\",\n",
    "        \"answer\": \"In automatic mode, the UE searches for and selects a PLMN based on pre-configured priority lists or previously stored information. In manual mode, the user selects the PLMN from a list of available networks provided by the UE after scanning.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Explain the difference between 'acceptable cells' and 'suitable cells.'\",\n",
    "        \"answer\": \"Acceptable cells allow limited services, such as emergency calls and ETWS/CMAS notifications. Suitable cells support full network services and meet stricter criteria like being part of the registered or selected PLMN.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle cell reselection priorities during inter-RAT transitions?\",\n",
    "        \"answer\": \"The UE follows priority lists provided in system information or dedicated signaling. Frequencies with higher priorities are evaluated first, and measurements are conducted accordingly. Equal-priority cells are ranked based on signal strength and quality.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What parameters affect cell reselection in the presence of high mobility?\",\n",
    "        \"answer\": \"Parameters like TCRmax, NCR_H, and speed-dependent scaling factors modify reselection timers (e.g., TreselectionNR) and hysteresis (Qhyst). In high-mobility states, scaling reduces reselection delays to ensure seamless transitions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Describe the relaxed measurement rules for cell reselection. When are they applied?\",\n",
    "        \"answer\": \"Relaxed measurement rules apply when the UE has low mobility or is not at the cell edge. Parameters like SSearchThresholdP and SSearchThresholdQ allow fewer measurements to conserve resources.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the role of CAG cells in the 5G system, and how does the UE select them?\",\n",
    "        \"answer\": \"CAG (Closed Access Group) cells are used for restricted access in private or enterprise networks. The UE selects these cells based on NAS-provided Allowed CAG lists and verifies that the CAG-ID matches the broadcast system information.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE process paging messages in RRC_IDLE versus RRC_INACTIVE?\",\n",
    "        \"answer\": \"In RRC_IDLE, the UE listens for paging in all tracking areas where it is registered. In RRC_INACTIVE, paging is restricted to a configured RNA (RAN-based Notification Area), reducing power consumption.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the significance of TreselectionNR, and how does it impact cell reselection?\",\n",
    "        \"answer\": \"TreselectionNR is a timer that defines the duration a target cell must meet reselection criteria before the UE reselects. It ensures stability by preventing rapid and unnecessary reselection events.\"\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"What is the impact of RNA updates in RRC_INACTIVE state?\",\n",
    "        \"answer\": \"RNA updates help maintain UE's context within a specific area, reducing signaling overhead and improving power efficiency.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE prioritize reselection between inter-frequency and intra-frequency cells?\",\n",
    "        \"answer\": \"Intra-frequency cells are prioritized if they fulfill the reselection criteria. Inter-frequency cells are considered if they have higher priority and better signal quality.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role do hysteresis parameters play in cell reselection?\",\n",
    "        \"answer\": \"Hysteresis parameters prevent frequent reselection by adding thresholds, ensuring stability in cell connections.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle paging in a multi-PLMN environment?\",\n",
    "        \"answer\": \"The UE listens for paging messages in all tracking areas associated with the selected PLMNs, optimizing response times.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What criteria does the UE use to evaluate sidelink communication suitability?\",\n",
    "        \"answer\": \"The UE evaluates parameters like signal strength, quality, and availability of sidelink configuration in system information broadcasts.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens if a UE fails to decode system information on a selected cell?\",\n",
    "        \"answer\": \"The UE continues searching for another suitable or acceptable cell to camp on, ensuring network availability.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How are measurement gaps used to enhance cell reselection accuracy?\",\n",
    "        \"answer\": \"Measurement gaps allow the UE to perform inter-frequency measurements without affecting its ongoing communication, improving reselection decisions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the role of PLMN identity in cell reselection?\",\n",
    "        \"answer\": \"PLMN identity ensures the UE selects cells belonging to its registered or equivalent networks, maintaining seamless connectivity.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle access control restrictions during cell selection?\",\n",
    "        \"answer\": \"The UE checks access control parameters like CAG identifiers and avoids restricted cells, ensuring compliance with network policies.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the significance of RSRP thresholds in reselection criteria?\",\n",
    "        \"answer\": \"RSRP thresholds define minimum signal strength requirements for a cell to be considered suitable, ensuring reliable connectivity.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why does the UE store frequency information during cell reselection?\",\n",
    "        \"answer\": \"Stored frequency information helps the UE expedite future reselection processes by avoiding redundant scans.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the advantages of DRX cycles for paging in idle mode?\",\n",
    "        \"answer\": \"DRX cycles reduce power consumption by allowing the UE to periodically wake up for paging checks, balancing responsiveness and efficiency.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE perform reselection when multiple cells have similar priority?\",\n",
    "        \"answer\": \"The UE ranks cells based on signal strength and quality, selecting the best cell among those with similar priority.\"\n",
    "    }]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"What happens during a tracking area update in the RRC_IDLE state?\",\n",
    "        \"answer\": \"The UE informs the network of its new location, ensuring accurate paging and network communication.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do reselection timers impact the UE's mobility handling?\",\n",
    "        \"answer\": \"Reselection timers like TreselectionNR delay transitions, ensuring the UE does not frequently switch cells unnecessarily.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role do SIB messages play in guiding UE behavior?\",\n",
    "        \"answer\": \"System Information Blocks (SIBs) provide critical configuration data like reselection parameters, enabling the UE to make informed decisions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE use signal quality metrics like RSRQ during reselection?\",\n",
    "        \"answer\": \"RSRQ evaluates the quality of the received signal, complementing signal strength metrics to ensure optimal reselection decisions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the significance of periodic searches for higher-priority PLMNs?\",\n",
    "        \"answer\": \"Periodic searches help the UE identify better networks, ensuring improved service quality and connectivity.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle reselection when operating in a shared spectrum?\",\n",
    "        \"answer\": \"The UE evaluates shared spectrum cells using additional metrics like load balancing and interference, optimizing reselection.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What triggers the UE to perform a cell reselection evaluation?\",\n",
    "        \"answer\": \"Triggers include changes in signal strength or quality, mobility events, or updated system information parameters.\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"How does the UE maintain context while transitioning between RRC states?\",\n",
    "        \"answer\": \"The UE stores essential parameters like RNTI and maintains an active signaling connection, ensuring quick state transitions.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the purpose of measurement configurations in 5G networks?\",\n",
    "        \"answer\": \"Measurement configurations define the conditions under which the UE performs signal strength and quality evaluations, ensuring optimal reselection.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why does the UE rely on periodicity timers for reselection measurements?\",\n",
    "        \"answer\": \"Periodicity timers ensure the UE performs regular checks on neighboring cells without excessive power consumption.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens when the UE encounters overlapping PLMN broadcasts?\",\n",
    "        \"answer\": \"The UE prioritizes PLMNs based on stored preferences or user input to select the most suitable network.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the function of mobility anchors in inter-RAT handovers?\",\n",
    "        \"answer\": \"Mobility anchors provide seamless connectivity by maintaining data sessions while the UE transitions between RATs.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does UE behavior change in areas with sparse network coverage?\",\n",
    "        \"answer\": \"The UE increases measurement activities and may camp on acceptable cells to maintain basic connectivity.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role does NR-ARFCN play in cell selection and reselection?\",\n",
    "        \"answer\": \"NR-ARFCN provides the frequency reference for UE to identify and measure candidate cells during reselection.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE manage reselection during high-speed mobility?\",\n",
    "        \"answer\": \"The UE uses speed-dependent scaling factors and prioritizes measurements on higher-priority frequencies to reduce reselection latency.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What information is conveyed in SIB1 to guide cell reselection?\",\n",
    "        \"answer\": \"SIB1 provides parameters like cell barring, intra-frequency priority, and thresholds for reselection.\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why is power-saving crucial in idle and inactive modes?\",\n",
    "        \"answer\": \"Power-saving mechanisms like DRX and RNA configuration ensure extended battery life while maintaining connectivity readiness.\" \n",
    "    }\n",
    "]\n",
    "'''\n",
    "'''\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"How does the UE evaluate neighboring cell performance during handovers?\",\n",
    "        \"answer\": \"The UE uses signal measurements like RSRP and RSRQ to evaluate and compare neighboring cell performance.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role do beamforming techniques play in 5G connectivity?\",\n",
    "        \"answer\": \"Beamforming improves signal strength and quality by focusing transmission and reception in specific directions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How are priority levels assigned to frequency bands in 5G?\",\n",
    "        \"answer\": \"Priority levels are configured by the network and broadcast through system information to guide UE behavior.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the significance of the serving cell in NR networks?\",\n",
    "        \"answer\": \"The serving cell provides the primary connection for the UE, facilitating data transfer and control signaling.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE ensure seamless handovers during mobility?\",\n",
    "        \"answer\": \"The UE performs measurements and reports them to the network, which decides and executes the handover process.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What parameters affect the UE's paging cycle in idle mode?\",\n",
    "        \"answer\": \"Parameters like DRX cycle length and paging occasion configuration affect how often the UE wakes to check for pages.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens when a UE fails to complete a handover?\",\n",
    "        \"answer\": \"The UE reverts to the source cell or attempts to reconnect to the network to maintain service continuity.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the purpose of SIB2 in NR networks?\",\n",
    "        \"answer\": \"SIB2 contains cell-specific configuration details, such as reselection thresholds and access control information.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE identify barred cells during cell selection?\",\n",
    "        \"answer\": \"The UE decodes system information to check for barring status and avoids camping on barred cells.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the implications of using shared spectrum for UE connectivity?\",\n",
    "        \"answer\": \"Shared spectrum can increase network efficiency but requires the UE to handle dynamic resource allocation and interference.\"\n",
    "    }\n",
    "]\n",
    "'''\n",
    "'''\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"What mechanisms does the UE use to ensure reliable connectivity during inter-frequency reselection?\",\n",
    "        \"answer\": \"The UE uses thresholds like ThreshX,HighQ and performs measurements on candidate frequencies to ensure seamless reselection.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle inter-RAT reselection between 5G and LTE?\",\n",
    "        \"answer\": \"The UE evaluates inter-RAT priority configurations and performs signal quality checks before switching.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What factors influence the UE's choice of tracking area?\",\n",
    "        \"answer\": \"Tracking area selection depends on parameters like signal strength, mobility, and network-defined configurations.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why are RAN-based notification areas important in RRC_INACTIVE state?\",\n",
    "        \"answer\": \"They minimize paging overhead by restricting notifications to a subset of cells where the UE is likely located.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens when a UE detects a barred tracking area?\",\n",
    "        \"answer\": \"The UE avoids camping on cells within the barred tracking area and searches for alternative suitable cells.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE process paging messages for emergency services?\",\n",
    "        \"answer\": \"The UE treats all acceptable cells as suitable and processes emergency paging even on non-registered PLMNs.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What criteria are evaluated for reselection in shared spectrum operations?\",\n",
    "        \"answer\": \"The UE considers interference levels, priority configurations, and load balancing metrics.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do mobility states affect reselection timers like TreselectionNR?\",\n",
    "        \"answer\": \"Higher mobility states reduce the timers, allowing faster reselection to adapt to rapid signal changes.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the role of QoffsetFreq in inter-frequency reselection?\",\n",
    "        \"answer\": \"QoffsetFreq adjusts the measured signal quality of a frequency, influencing its ranking during reselection.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why is signal quality critical in 5G reselection decisions?\",\n",
    "        \"answer\": \"Signal quality metrics like Squal ensure the UE connects to cells with reliable and efficient service levels.\"\n",
    "    }\n",
    "]\n",
    "'''\n",
    "'''\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"What is the impact of RNA updates in RRC_INACTIVE state?\",\n",
    "        \"answer\": \"RNA updates help maintain UE's context within a specific area, reducing signaling overhead and improving power efficiency.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE prioritize reselection between inter-frequency and intra-frequency cells?\",\n",
    "        \"answer\": \"Intra-frequency cells are prioritized if they fulfill the reselection criteria. Inter-frequency cells are considered if they have higher priority and better signal quality.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role do hysteresis parameters play in cell reselection?\",\n",
    "        \"answer\": \"Hysteresis parameters prevent frequent reselection by adding thresholds, ensuring stability in cell connections.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle paging in a multi-PLMN environment?\",\n",
    "        \"answer\": \"The UE listens for paging messages in all tracking areas associated with the selected PLMNs, optimizing response times.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What criteria does the UE use to evaluate sidelink communication suitability?\",\n",
    "        \"answer\": \"The UE evaluates parameters like signal strength, quality, and availability of sidelink configuration in system information broadcasts.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens if a UE fails to decode system information on a selected cell?\",\n",
    "        \"answer\": \"The UE continues searching for another suitable or acceptable cell to camp on, ensuring network availability.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How are measurement gaps used to enhance cell reselection accuracy?\",\n",
    "        \"answer\": \"Measurement gaps allow the UE to perform inter-frequency measurements without affecting its ongoing communication, improving reselection decisions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the role of PLMN identity in cell reselection?\",\n",
    "        \"answer\": \"PLMN identity ensures the UE selects cells belonging to its registered or equivalent networks, maintaining seamless connectivity.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle access control restrictions during cell selection?\",\n",
    "        \"answer\": \"The UE checks access control parameters like CAG identifiers and avoids restricted cells, ensuring compliance with network policies.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the significance of RSRP thresholds in reselection criteria?\",\n",
    "        \"answer\": \"RSRP thresholds define minimum signal strength requirements for a cell to be considered suitable, ensuring reliable connectivity.\"\n",
    "    }\n",
    "]\n",
    "'''\n",
    "'''\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"How does the UE adapt to power-saving mechanisms during idle mode?\",\n",
    "        \"answer\": \"The UE utilizes features like Discontinuous Reception (DRX) cycles and monitors only specific paging occasions to save battery power.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens during inter-frequency reselection when thresholds are met?\",\n",
    "        \"answer\": \"The UE evaluates the target frequency’s quality parameters like Srxlev and Squal before completing the reselection process.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE maintain connectivity in dense urban environments?\",\n",
    "        \"answer\": \"The UE frequently measures and ranks cells to ensure it connects to the most reliable network amidst fluctuating signals.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role does system information play in guiding UE reselection?\",\n",
    "        \"answer\": \"System Information Blocks (SIBs) broadcast critical data like reselection thresholds and frequency priorities to assist UE decision-making.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE avoid frequent reselection events in high-mobility scenarios?\",\n",
    "        \"answer\": \"The UE applies hysteresis margins and speed-based scaling to stabilize connections and reduce unnecessary reselection.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What mechanisms ensure reliable handovers between LTE and 5G?\",\n",
    "        \"answer\": \"The UE uses dual connectivity and mobility anchors to manage seamless transitions across RATs without service disruption.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why does the UE periodically recheck the serving cell in idle mode?\",\n",
    "        \"answer\": \"Periodic checks verify that the serving cell still meets quality requirements and allows the UE to detect better alternatives if available.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What factors influence the UE’s paging response time?\",\n",
    "        \"answer\": \"Paging response time depends on DRX configurations, the size of the paging group, and network congestion levels.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE determine whether a cell is barred or reserved?\",\n",
    "        \"answer\": \"The UE decodes broadcast information like barred cell identifiers or access control parameters to identify restricted cells.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the significance of TreselectionEUTRA in 5G systems?\",\n",
    "        \"answer\": \"TreselectionEUTRA ensures that the UE meets specific criteria for stability before moving to an LTE cell during inter-RAT transitions.\"\n",
    "    }\n",
    "]\n",
    "'''\n",
    "'''\n",
    "questions_answers = [\n",
    "    {\n",
    "        \"question\": \"What happens when a UE detects overlapping RNAs during RRC_INACTIVE?\",\n",
    "        \"answer\": \"The UE resolves overlapping RNA configurations by selecting the one with the highest priority or signal quality.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE evaluate emergency cell broadcasts?\",\n",
    "        \"answer\": \"Emergency cells are prioritized based on acceptability, allowing the UE to connect even when normal reselection criteria are not met.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role do network slicing configurations play in cell reselection?\",\n",
    "        \"answer\": \"Network slicing provides dedicated resources for specific applications, influencing the UE’s reselection decisions based on slice priority.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle dual connectivity between LTE and NR?\",\n",
    "        \"answer\": \"The UE simultaneously maintains connections with both LTE and NR to enhance data throughput and handover reliability.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What mechanisms are used to avoid ping-pong reselections?\",\n",
    "        \"answer\": \"Hysteresis and reselection timers like Treselection prevent the UE from oscillating between cells with similar signal conditions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What factors trigger a UE to perform periodic reselection measurements?\",\n",
    "        \"answer\": \"Periodic reselection measurements are triggered by timers or changes in network configurations to ensure the UE is connected to the best cell.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE respond to system information updates in idle mode?\",\n",
    "        \"answer\": \"The UE decodes updated system information and adjusts its reselection parameters or behaviors accordingly.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the significance of Qrxlevmin in cell reselection?\",\n",
    "        \"answer\": \"Qrxlevmin defines the minimum required signal strength for a cell to be considered suitable, ensuring stable connectivity.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle reselection in a network with mixed TDD and FDD deployments?\",\n",
    "        \"answer\": \"The UE evaluates the signal quality and configuration of both TDD and FDD cells, selecting the one that offers better service.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What happens when the UE moves to a low-priority PLMN during mobility?\",\n",
    "        \"answer\": \"The UE continues monitoring for higher-priority PLMNs and reselects to them when their criteria are met.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE balance power consumption and reselection accuracy?\",\n",
    "        \"answer\": \"The UE optimizes measurement intervals and uses relaxed thresholds in low-mobility scenarios to balance power usage and accuracy.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role do beam measurements play in NR reselection?\",\n",
    "        \"answer\": \"Beam measurements help the UE identify the strongest beams in an NR cell, improving the quality of its reselection decisions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE process forbidden tracking area lists during reselection?\",\n",
    "        \"answer\": \"The UE avoids cells in forbidden tracking areas, ensuring compliance with network restrictions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role does mobility history play in reselection decisions?\",\n",
    "        \"answer\": \"Mobility history allows the UE to prioritize cells or frequencies that have previously provided stable connections.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why is SIB12 crucial in public warning systems?\",\n",
    "        \"answer\": \"SIB12 carries configuration for public warning notifications, ensuring the UE can receive critical alerts.\"\n",
    "    }\n",
    "]\n",
    "'''\n",
    "\"\"\"\n",
    "questions_answers = [{\n",
    "        \"question\": \"What impact does the frequency band have on reselection speed?\",\n",
    "        \"answer\": \"Lower frequency bands typically have better coverage, leading to quicker reselection in areas with poor high-frequency coverage.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE prioritize reselection between public and private networks?\",\n",
    "        \"answer\": \"The UE uses network priority configurations broadcast in system information to decide between public and private networks.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What role does backoff timing play in reselection after failed attempts?\",\n",
    "        \"answer\": \"Backoff timing prevents the UE from repeatedly attempting to reselect a cell that previously failed, improving overall network efficiency.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the UE handle reselection in multi-operator core networks (MOCN)?\",\n",
    "        \"answer\": \"The UE evaluates the PLMN configurations within the shared network and selects based on its operator’s priority.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why is reselection performance crucial in high-speed mobility scenarios?\",\n",
    "        \"answer\": \"Fast and accurate reselection ensures uninterrupted service, especially when the UE is moving quickly between cells.\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "# Combine all question lists\n",
    "#questions_answers +=   additional_questions\n",
    "#questions_answers += new_questions\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "llmsan = ChatOpenAI(base_url=\"https://api.sambanova.ai/v1/\",\n",
    "                 api_key = os.environ['SAMBANOVA_API_KEY'],\n",
    "                 streaming=True,\n",
    "                 model = \"Meta-Llama-3.2-3B-Instruct\")\n",
    "\n",
    "llm = ChatOllama(\n",
    "                 model = \"llama3.2\")\n",
    "\n",
    "\n",
    "# Sonuçları saklamak için bir liste\n",
    "evaluation_results = []\n",
    "\n",
    "# Her bir input üzerinde işlem yapma\n",
    "\n",
    "for qa_pair in questions_answers:\n",
    "    question = qa_pair[\"question\"]\n",
    "    ground_truth = qa_pair[\"answer\"]\n",
    "    # similarity_search çıktısını stringe dönüştür\n",
    "    retrieved_contexts = vectorstore.similarity_search(question, k=10)\n",
    "    combined_context = \" \".join([doc.page_content for doc in retrieved_contexts])\n",
    "\n",
    "    truncated_context = truncate_to_token_limit((combined_context), token_limit=4000)\n",
    "    input_message = HumanMessage(content=f\"Context: {truncated_context}\\n\\nQuestion: {question}\")\n",
    "    response = llmsan.invoke([input_message])\n",
    "    # Değerlendirme prompt'unu hazırlama\n",
    "    grader_prompt = GRADER_PROMPT_TEMPLATE.format(\n",
    "                    context=retrieved_contexts,\n",
    "                    question=question,\n",
    "                    response=response.content,\n",
    "                    ground_truth=ground_truth\n",
    "                                                )\n",
    "    \n",
    "    # LLM for Evaluation SanBanova\n",
    "    evaluation_result = llmsan.invoke(grader_prompt)\n",
    "    \n",
    "    # Sonuçları saklama\n",
    "    evaluation_results.append({\n",
    "        \"query\": question,\n",
    "        \"response\": response,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"evaluation\": evaluation_result.content\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c169e7-f174-429d-aeb4-844620826343",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(f\"Question:{question}\")\n",
    "    print(f\"Response:{response}\")\n",
    "    print(f\"Ground Truth:{ground_truth}\")\n",
    "    print(f\"Context:{evaluation_result.content}\")\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d765e2a-0414-408c-bcd0-5873ab0aabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Prepare the header for the CSV file\n",
    "csv_header = [\n",
    "    \"Question\", \n",
    "    \"Ground Truth\", \n",
    "    \"Context\", \n",
    "    \"Groundedness\", \n",
    "    \"Answer Relevance\", \n",
    "    \"Context Relevance\"\n",
    "]\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"evaluation_results.csv\"\n",
    "\n",
    "# Initialize lists to store scores for average calculation\n",
    "groundedness_scores = []\n",
    "answer_relevance_scores = []\n",
    "context_relevance_scores = []\n",
    "\n",
    "# Check if the file already exists\n",
    "file_exists = os.path.exists(csv_file_path)\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file_path, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header only if the file is new\n",
    "    if not file_exists:\n",
    "        writer.writerow(csv_header)\n",
    "    \n",
    "    # Loop through the evaluation results and write each one to the CSV\n",
    "    for result in evaluation_results:\n",
    "        # Extract the scores and context from the evaluation result\n",
    "        evaluation = result[\"evaluation\"]\n",
    "        \n",
    "        # Parse the evaluation string to extract the individual scores\n",
    "        scores = {}\n",
    "        for line in evaluation.split(\"\\n\"):\n",
    "            if line.startswith(\"Groundedness\"):\n",
    "                scores[\"Groundedness\"] = float(line.split(\":\")[1].strip().split(\"/\")[0])  # Extract before \"/\"\n",
    "            elif line.startswith(\"Answer Relevance\"):\n",
    "                scores[\"Answer Relevance\"] = float(line.split(\":\")[1].strip().split(\"/\")[0])  # Extract before \"/\"\n",
    "            elif line.startswith(\"Context Relevance\"):\n",
    "                scores[\"Context Relevance\"] = float(line.split(\":\")[1].strip().split(\"/\")[0])  # Extract before \"/\"\n",
    "\n",
    "        # Write the row to the CSV\n",
    "        writer.writerow([\n",
    "            result[\"query\"], \n",
    "            result[\"ground_truth\"], \n",
    "            result[\"response\"].content,  # assuming the response content is the string to be saved\n",
    "            scores.get(\"Groundedness\", \"\"),\n",
    "            scores.get(\"Answer Relevance\", \"\"),\n",
    "            scores.get(\"Context Relevance\", \"\")\n",
    "        ])\n",
    "        \n",
    "        # Accumulate the scores for averaging\n",
    "        groundedness_scores.append(scores.get(\"Groundedness\", 0))\n",
    "        answer_relevance_scores.append(scores.get(\"Answer Relevance\", 0))\n",
    "        context_relevance_scores.append(scores.get(\"Context Relevance\", 0))\n",
    "\n",
    "print(f\"Results appended to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6462d5a-ac88-4f54-aab4-327d0358048e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecaae4-ee58-4baf-886e-483b186c8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını yükleyin\n",
    "df = pd.read_csv('evaluation_results.csv')\n",
    "\n",
    "# İlgili sütunu yazdırın (örneğin 'sütun_adı' sütunu)\n",
    "\n",
    "print(df['Context Relevance'].mean())\n",
    "print(df['Answer Relevance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf804bc-d4b0-4952-bf60-e959c02b1d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
